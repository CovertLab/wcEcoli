import os
import csv
from reconstruction import spreadsheets
from functools import partial
import numpy as np
import time
import random

DIALECT = "excel-tab"
JsonReader = partial(spreadsheets.JsonReader, dialect = DIALECT)
JsonWriter = partial(spreadsheets.JsonWriter, dialect = DIALECT)


chunk_size = 5
polycistron_file = '/Users/taryn/GoogleDrive/code/wcEcoli/prototypes/operons/polycistron_chunks_shuffled/polycistron_file_chunk_shuffled0.tsv'
output_dir = 'prototypes/operons/polycistron_chunks_shuffled/chunk_0/'
file_basename = 'polycistron_file_chunk_shuffled_0_'

if not os.path.isdir(output_dir):
    os.mkdir(output_dir)


# read in initial file
with open(polycistron_file) as f:
    reader = JsonReader(f)
    pc_file_data = []
    for row in reader:
        pc_file_data.append(list(row.values()))

random.shuffle(pc_file_data)
# loop and create chunks of specified size
num_lines = len(pc_file_data)
num_chunks = int(np.ceil(num_lines/chunk_size))
start_idx = 0
end_idx = chunk_size
fieldnames = ["transcription_units", "monomers_to_remove"]

for i in range(0, num_chunks):

    out_file = output_dir + file_basename + str(i) + '.tsv'
    with open (out_file, 'w') as f:
        writer = JsonWriter(f, fieldnames, dialect=csv.excel_tab)
        writer.writeheader()
        for pc_idx in range(start_idx, end_idx):
            try:
                writer.writerow(dict(zip(fieldnames, pc_file_data[pc_idx])))
            except:
                import ipdb; ipdb.set_trace()
        start_idx += chunk_size
        end_idx += chunk_size
        end_idx = min(num_lines, end_idx)

#
# with open(output_dir + 'info.tsv', 'w') as f:
#     writer = csv.writer(f, delimiter='\t')
#     writer.writerow(['path to original polycistron file: ' + polycistron_file])
#     writer.writerow(['Generated by {} on {} \n'.format(__file__, time.ctime())])