{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "os.chdir(os.path.expanduser('~/wcEcoli/'))\n",
    "# noinspection PyUnresolvedReferences\n",
    "from wholecell.io.tablereader import TableReader\n",
    "import io\n",
    "import numpy as np\n",
    "from wholecell.io import tsv\n",
    "from wholecell.utils.filepath import ROOT_PATH\n",
    "import plotly.graph_objects as go\n",
    "from models.ecoli.analysis import cohortAnalysisPlot\n",
    "from wholecell.analysis.analysis_tools import (exportFigure,\n",
    "\tread_bulk_molecule_counts, read_stacked_bulk_molecules, read_stacked_columns)\n",
    "from wholecell.io.tablereader import TableReader\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import plotly.express as px"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Specify the data sequences to compare",
   "id": "5f21f3deb4e54744"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Name the sequences to use:\n",
    "current_sequence = \"Clim4_STD_ratio_threshold_2_keep_NaNs\"\n",
    "CLNE_sequence = \"CLNE3\"\n",
    "branch_name = \"pd-half-life-debug\""
   ],
   "id": "91d11cca95bd47b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "some functions that will be used for data processing: ",
   "id": "9c46899717f9f6ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# function to match gene symbols to monomer ids\n",
    "def get_gene_symbols_for_monomer_ids():\n",
    "\t\"\"\"\n",
    "\tExtracts the gene symbols for each monomer id in the model.\n",
    "\tReturns: a dictionary mapping monomer ids to gene symbols.\n",
    "\tCode adapted from convert_to_flat.py.\n",
    "\t\"\"\"\n",
    "\tRNAS_FILE = os.path.join(ROOT_PATH, 'reconstruction', 'ecoli',\n",
    "\t\t\t\t\t\t\t\t 'flat', 'rnas.tsv')\n",
    "\twith (io.open(RNAS_FILE, 'rb') as f):\n",
    "\t\treader = tsv.reader(f, delimiter='\\t')\n",
    "\t\theaders = next(reader)\n",
    "\t\twhile headers[0].startswith('#'):\n",
    "\t\t\theaders = next(reader)\n",
    "\n",
    "\t\t# extract relevant information\n",
    "\t\tgene_symbol_index = headers.index('common_name')\n",
    "\t\tprotein_id_index = headers.index('monomer_ids')\n",
    "\t\tmonomer_ids_to_gene_symbols = {}\n",
    "\t\tfor line in reader:\n",
    "\t\t\tgene_symbol = line[gene_symbol_index]\n",
    "\t\t\tprotein_id = list(\n",
    "\t\t\t\tline[protein_id_index][2:-2].split('\", \"'))[0]\n",
    "\t\t\tmonomer_ids_to_gene_symbols[protein_id] = gene_symbol\n",
    "\n",
    "\treturn monomer_ids_to_gene_symbols\n",
    "\n",
    "def get_common_name(protein_id):\n",
    "    \"\"\"\n",
    "    Get the common name of a protein given its monomer id.\n",
    "    Args:\n",
    "        protein_id: the name of the monomer\n",
    "\n",
    "    Returns:\n",
    "        common_name: The common name of the protein.\n",
    "\n",
    "    \"\"\"\n",
    "    # remove the compartment tag first if it exists:\n",
    "    if '[' in protein_id:\n",
    "        protein_id = protein_id[:-3]  # subtract the compartment\n",
    "        common_name = get_gene_symbols_for_monomer_ids()[protein_id]\n",
    "    else:\n",
    "        common_name = get_gene_symbols_for_monomer_ids()[protein_id]\n",
    "    return common_name"
   ],
   "id": "7c312242882b29d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read in all the data\n",
   "id": "ad9ebf6c85449f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# read in the CLNE (2020 model) half life data: \n",
    "CLNE1_HLs = f\"out/{CLNE_sequence}/kb_plot_out/protein_half_lives.tsv\"\n",
    "CLNE1_HLs = pd.read_csv(CLNE1_HLs, sep='\\t')\n",
    "CLNE1_HLs = CLNE1_HLs.rename(columns={\"half_life_(min)\": \"original_half_life\"})\n",
    "CLNE1_HLs = CLNE1_HLs.drop(columns={\"degradation_rate(1/s)\", \"degradation_rate_source\"})\n",
    "\n",
    "# read in the CLClim3NE (2025 model) half life data:\n",
    "CLClim3NE1_HLs = f\"out/{current_sequence}/kb_plot_out/protein_half_lives.tsv\"\n",
    "CLClim3NE1_HLs = pd.read_csv(CLClim3NE1_HLs, sep='\\t')\n",
    "CLClim3NE1_HLs = CLClim3NE1_HLs.rename(columns={\"half_life_(min)\": \"new_half_life\"})\n",
    "CLClim3NE1_HLs = CLClim3NE1_HLs.drop(columns={\"degradation_rate(1/s)\", \"degradation_rate_source\"})\n",
    "\n",
    "# merge the two together: \n",
    "combined_df = pd.merge(CLClim3NE1_HLs, CLNE1_HLs, on='monomer_id', how='inner')\n",
    "\n",
    "# add the common names to the dataframe:\n",
    "combined_df['common_name'] = None\n",
    "for index, row in combined_df.iterrows():\n",
    "    common_name = get_common_name(row['monomer_id'])\n",
    "    combined_df.at[index, 'common_name'] = common_name\n",
    "\n",
    "# add the counts data: \n",
    "CLNE_new_name = \"Log10 \" +CLNE_sequence +\" Average Monomer Counts\"\n",
    "CLClimNE_new_name = \"Log10 \" +current_sequence +\" Average Monomer Counts\"\n",
    "\n",
    "# read in the unfiltered data and remove the last three characters from each entry in the Monomer ID column: \n",
    "CLClimNE_log_data = pd.read_csv(\n",
    "    f'out/{current_sequence}/wildtype_000000/cohort_average_monomer_count_data/unfiltered_data/log_data/LogAvgProteinCounts_startGen_2.csv')\n",
    "CLClimNE_log_data['Monomer ID'] = CLClimNE_log_data['Monomer ID'].str[:-3]\n",
    "\n",
    "# do the same for the 2020 model:\n",
    "CLNE_log_data = pd.read_csv('/Users/miagrahn/wcEcoli/out/CLNE_11192024/wildtype_000000/cohort_average_monomer_count_data/unfiltered_data/log_data/LogAvgProteinCounts_startGen_2.csv')\n",
    "CLNE_log_data['Monomer ID'] = CLNE_log_data['Monomer ID'].str[:-3]\n",
    "\n",
    "# merge the two dataframes:\n",
    "CLNE_log_data = CLNE_log_data.rename(columns={\"Log10 Average Monomer Counts\": CLNE_new_name})\n",
    "CLClimNE_log_data = CLClimNE_log_data.rename(columns={\"Log10 Average Monomer Counts\": CLClimNE_new_name})\n",
    "CLNE_log_data = CLNE_log_data.set_index(\"Monomer ID\")\n",
    "CLClimNE_log_data = CLClimNE_log_data.set_index(\"Monomer ID\")\n",
    "# CLNE_log_data = CLNE_log_data.reset_index()\n",
    "# CLClimNE_log_data = CLClimNE_log_data.reset_index()\n",
    "CLNE_CLClimNE_log_data = CLNE_log_data.join(CLClimNE_log_data, on=\"Monomer ID\", how=\"inner\")\n",
    "CLNE_CLClimNE_log_data = CLNE_CLClimNE_log_data.reset_index()\n",
    "CLNE_CLClimNE_log_data = CLNE_CLClimNE_log_data.rename(columns={\"Monomer ID\": \"monomer_id\"})\n",
    "#CLNE_CLClimNE_log_data = CLNE_CLClimNE_log_data.set_index(\"monomer_id\")\n",
    "\n",
    "\n",
    "# merge into combined_df:\n",
    "combined_df = pd.merge(combined_df, CLNE_CLClimNE_log_data, on='monomer_id', how='inner')\n",
    "\n",
    "# add new half life (HL) columns: \n",
    "# find the differences between the orginal half life and the new half life:\n",
    "combined_df['HL_difference'] = combined_df['new_half_life'] - combined_df['original_half_life']\n",
    "# make a new column that is the fold change in half life:\n",
    "combined_df['HL_fold_change'] = combined_df['new_half_life'] / combined_df['original_half_life']\n",
    "# calcuate the log 2 fold change:\n",
    "combined_df['HL_log2_fold_change'] = np.log2(combined_df['HL_fold_change'])\n",
    "\n",
    "# add new protein count (PC) columns:\n",
    "# find the differences between the orginal protein counts and the new protein counts:\n",
    "combined_df['PC_difference'] = 10**(combined_df[CLClimNE_new_name]) - 10**(combined_df[CLNE_new_name])\n",
    "# make a new column that is the fold change in protein counts:\n",
    "combined_df['PC_fold_change'] = 10**(combined_df[CLClimNE_new_name]) / 10**(combined_df[CLNE_new_name])\n",
    "# calcuate the log 2 fold change:\n",
    "combined_df['PC_log2_fold_change'] = np.log2(combined_df['PC_fold_change'])\n",
    "\n",
    "combined_df['counts_new_+10'] = np.log10(10**(combined_df[CLClimNE_new_name]) + 9) # +9 becuase in the save data, i added +1 already\n",
    "combined_df['counts_old_+10'] = np.log10(10**(combined_df[CLNE_new_name]) + 9)\n",
    "combined_df['log2_counts_10'] = np.log2(combined_df['counts_new_+10'] / combined_df['counts_old_+10'])\n",
    "\n",
    "\n",
    "# now add in the validation data... AHHH! \n",
    "# read in the unfiltered data and remove the last three characters from each entry in the Monomer ID column: \n",
    "CLClimNE_log_validaiton_data = pd.read_csv(\n",
    "    f'out/{current_sequence}/wildtype_000000/cohort_average_monomer_count_data/validation_data/log_data/Log10_Schmidt_Comparison_startGen_2.csv')\n",
    "CLClimNE_log_validaiton_data['Monomer ID'] = CLClimNE_log_validaiton_data['Monomer ID'].str[:-3]\n",
    "\n",
    "combined_df['Log10 Validation Data Average Monomer Counts'] = None\n",
    "for index, row in combined_df.iterrows():\n",
    "    monomer_id = row['monomer_id']\n",
    "    # Check if the monomer_id exists in the validation data\n",
    "    if monomer_id in CLClimNE_log_validaiton_data['Monomer ID'].values:\n",
    "        # Get the corresponding value from the validation data\n",
    "        validation_value = CLClimNE_log_validaiton_data.loc[CLClimNE_log_validaiton_data['Monomer ID'] == monomer_id, 'Log10 Schmidt Validation Counts'].values[0]\n",
    "        combined_df.at[index, 'Log10 Validation Data Average Monomer Counts'] = validation_value\n",
    "    else: \n",
    "        # If the monomer_id is not found, you can choose to set it to NaN or some other value\n",
    "        combined_df.at[index, 'Log10 Validation Data Average Monomer Counts'] = None # do I need to do this? is it already happening?\n",
    "\n",
    "\n",
    "combined_df"
   ],
   "id": "947f6518a74efd9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate the log2 fold change in HL plot\n",
   "id": "fd5c7a2b97f9c83f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the data to use: \n",
    "df = combined_df.copy()\n",
    "\n",
    "# define column to plot: \n",
    "column = 'HL_log2_fold_change'\n",
    "\n",
    "# define bounds for changes\n",
    "upper = 2\n",
    "middle = 0\n",
    "lower = -3\n",
    "\n",
    "# define the name of the file: \n",
    "out_pth = f\"out/figures/PDR_UPDATE_MERGE/F2/change_in_half_life_histograms/log2_fold_change_in_HL_values_with_all_proteins_[{lower},{middle},{upper}]_{current_sequence}_{CLNE_sequence}.png\"\n",
    "\n",
    "# define the title of the plot:\n",
    "title0 = f'The log2 fold change of the half life value \\n between the 2020 model and the 2025 model (n={df.shape[0]})'\n",
    "\n",
    "# find all of the half lives that are greater than 800:\n",
    "CLClim3NE1_HLs_Clim3_above_upper = df[df[column] > upper] # \n",
    "CLClim3NE1_HLs_Clim3_above_upper = CLClim3NE1_HLs_Clim3_above_upper.copy()\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"sort_color\"] = \"red\"\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"column_width\"] = \"1\"\n",
    "words_u = f'greater than {upper}: {CLClim3NE1_HLs_Clim3_above_upper.shape[0]}'\n",
    "print(words_u)\n",
    "\n",
    "# find all the half lives between 800 and 0: \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = df[(df[column] <= upper) & (df[column] > middle)] # \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = CLClim3NE1_HLs_Clim3_upper_to_zero.copy()\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"sort_color\"] = \"orange\"\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"column_width\"] = \"4\"\n",
    "words_u2m = f'between {upper} and {middle}: {CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}'\n",
    "print(words_u2m)\n",
    "\n",
    "CLClim3NE1_HLs_Clim3_middle = df[df[column] == middle ] #\n",
    "CLClim3NE1_HLs_Clim3_middle = CLClim3NE1_HLs_Clim3_middle.copy()\n",
    "CLClim3NE1_HLs_Clim3_middle[\"sort_color\"] = \"green\"\n",
    "CLClim3NE1_HLs_Clim3_middle[\"column_width\"] = \"4\"\n",
    "words_m = f'exactly {middle}: {CLClim3NE1_HLs_Clim3_middle.shape[0]}'\n",
    "print(words_m)\n",
    "\n",
    "# find all half lives between 600 and 200: \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = df[(df[column] < middle) & (df[column] > lower)] # \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = CLClim3NE1_HLs_Clim3_0_to_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"sort_color\"] = \"lightblue\"\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"column_width\"] = \"4\"\n",
    "words_m2l = f'between {middle} and {lower}: {CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}'\n",
    "print(words_m2l)\n",
    "\n",
    "# find all the half lives between 200 and 0:\n",
    "CLClim3NE1_HLs_Clim3_lower = df[(df[column] <= lower)] # \n",
    "CLClim3NE1_HLs_Clim3_lower = CLClim3NE1_HLs_Clim3_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_lower[\"sort_color\"] = \"blue\"\n",
    "CLClim3NE1_HLs_Clim3_lower[\"column_width\"] = \"1\"\n",
    "words_l = f'less than {lower}: {CLClim3NE1_HLs_Clim3_lower.shape[0]}'\n",
    "print(words_l)\n",
    "\n",
    "\n",
    "# make a new data frame that is more simple\n",
    "# concatenate the data frames together:\n",
    "CLClim3NE1_HLs_Clim3_split_protein_difference = pd.concat([CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_lower], ignore_index=True)\n",
    "data = CLClim3NE1_HLs_Clim3_split_protein_difference[['common_name', column,'sort_color', 'column_width']]\n",
    "\n",
    "# add a new rows to the data: \n",
    "new_rows = [\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}',\n",
    "        column: upper,\n",
    "        'sort_color': 'orange',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_middle.shape[0]}',\n",
    "        column: middle + 0.5,\n",
    "        'sort_color': 'green',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}',\n",
    "        column: lower,\n",
    "        'sort_color': 'lightblue',\n",
    "        'column_width': 4\n",
    "    }\n",
    "]\n",
    "\n",
    "# convert new rows to a DataFrame:\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "data = pd.concat([data, new_rows_df], ignore_index=True)\n",
    "\n",
    "# sort the data\n",
    "data = data.sort_values(by=[column], ascending=False)\n",
    "data.set_index('common_name', inplace=True)\n",
    "\n",
    "\n",
    "# create a color dictionary for the colors:\n",
    "color_dict = {'red': '#fd625e', 'orange': '#f9a825', 'green': 'green', 'lightblue': '#01b8aa', 'blue': '#0d47a1'}\n",
    "\n",
    "# create a size dictionary for the sizes:\n",
    "size_dict = {'red': .1, 'orange': .5, 'green':1,'lightblue': .5, 'blue': .1}\n",
    "\n",
    "upper_len = int(CLClim3NE1_HLs_Clim3_above_upper.shape[0])\n",
    "lower_len = int(CLClim3NE1_HLs_Clim3_lower.shape[0])\n",
    "\n",
    "first_ticks = np.ones(upper_len) * size_dict['red']\n",
    "second_ticks = np.ones(1) * size_dict['orange']\n",
    "third_ticks = np.ones(1) * size_dict['green']\n",
    "fourth_ticks = np.ones(1) * size_dict['lightblue']\n",
    "fifth_ticks = np.ones(lower_len) * size_dict['blue']\n",
    "col_widths = [first_ticks, second_ticks, third_ticks, fourth_ticks, fifth_ticks]\n",
    "col_widths = np.concatenate(col_widths)\n",
    "col_widths\n",
    "\n",
    "# GET THE POSITIONS OF THE BARS\n",
    "# from: https://stackoverflow.com/questions/70477458/how-can-i-plot-bar-plots-with-variable-widths-but-without-gaps-in-python-and-ad\n",
    "a = 0\n",
    "x_positions = []\n",
    "for i in range(len(col_widths)):\n",
    "    if i == 0:\n",
    "        a+=col_widths[i]\n",
    "       \n",
    "        x_positions.append(col_widths[i]/2)\n",
    "        \n",
    "    else:\n",
    "        a += col_widths[i] + 0.05 # adding a gap \n",
    "       \n",
    "        x_positions.append(a - col_widths[i]/2)\n",
    "\n",
    "x_positions = np.array(x_positions)\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "index = data.index\n",
    "column0 = data[column]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20,10),  nrows=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "#axes.bar(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes.set_title(title0, fontsize=18, pad=15, )\n",
    "\n",
    "\n",
    "ticks_to_plot = []\n",
    "for i, val in enumerate(column0):\n",
    "    axes.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "    if data['sort_color'].iloc[i] == 'red':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'blue':\n",
    "        axes.text(x_positions[i], val - 0.35, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'green':\n",
    "        axes.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'orange':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$ $\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'lightblue':\n",
    "        axes.text(x_positions[i], val - .5, f\"-$\\\\Delta$ $\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "\n",
    "\n",
    "\n",
    "axes.set_ylabel('Log2 fold change in half life value\\n between the 2025 and 2020 model', fontsize=12, color=\"black\", )\n",
    "axes.set_xlabel('Proteins', fontsize=12, color=\"black\", )\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['bottom'].set_visible(False)\n",
    "axes.set_xticks([])\n",
    "axes.margins(x=0.0)\n",
    "\n",
    "#axes.set_ylim(-600, (lower + 2))  # cant do this here, should only do it when I do not have a shared x axis! \n",
    "\n",
    "# add a legend: \n",
    "#axes.legend(loc='upper right', fontsize=12, frameon=False, markerscale=2)\n",
    "axes.legend(\n",
    "    handles=[\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u, markerfacecolor=color_dict['red'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u2m, markerfacecolor=color_dict['orange'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m, markerfacecolor=color_dict['green'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m2l, markerfacecolor=color_dict['lightblue'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_l, markerfacecolor=color_dict['blue'], markersize=5)\n",
    "    ],\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    markerscale=2\n",
    ")   \n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n"
   ],
   "id": "3e1e14a6e5680aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate the log2 fold change protein count bar plot\n",
   "id": "b86aee7bc99f4ed2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the data to use: \n",
    "df = combined_df.copy()\n",
    "\n",
    "# define column to plot: \n",
    "column = 'PC_log2_fold_change'\n",
    "\n",
    "# define bounds for changes\n",
    "upper = 4\n",
    "middle = 0\n",
    "lower = -4\n",
    "\n",
    "# define the name of the file: \n",
    "out_pth = f\"out/figures/PDR_UPDATE_MERGE/F2/change_in_half_life_histograms/log2_fold_change_in_protein_count_values_with_all_proteins_[{lower},{middle},{upper}]_{current_sequence}_{CLNE_sequence}.png\"\n",
    "\n",
    "# define the title of the plot:\n",
    "title0 = f'Log2 fold change of the average protein counts \\n between the 2020 model and the 2025 model (n={df.shape[0]})'\n",
    "\n",
    "# find all of the half lives that are greater than 800:\n",
    "CLClim3NE1_HLs_Clim3_above_upper = df[df[column] > upper] # \n",
    "CLClim3NE1_HLs_Clim3_above_upper = CLClim3NE1_HLs_Clim3_above_upper.copy()\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"sort_color\"] = \"red\"\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"column_width\"] = \"1\"\n",
    "words_u = f'greater than {upper}: {CLClim3NE1_HLs_Clim3_above_upper.shape[0]}'\n",
    "print(words_u)\n",
    "\n",
    "# find all the half lives between 800 and 0: \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = df[(df[column] <= upper) & (df[column] > middle)] # \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = CLClim3NE1_HLs_Clim3_upper_to_zero.copy()\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"sort_color\"] = \"orange\"\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"column_width\"] = \"4\"\n",
    "words_u2m = f'between {upper} and {middle}: {CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}'\n",
    "print(words_u2m)\n",
    "\n",
    "CLClim3NE1_HLs_Clim3_middle = df[df[column] == middle ] #\n",
    "CLClim3NE1_HLs_Clim3_middle = CLClim3NE1_HLs_Clim3_middle.copy()\n",
    "CLClim3NE1_HLs_Clim3_middle[\"sort_color\"] = \"green\"\n",
    "CLClim3NE1_HLs_Clim3_middle[\"column_width\"] = \"4\"\n",
    "words_m = f'exactly {middle}: {CLClim3NE1_HLs_Clim3_middle.shape[0]}'\n",
    "print(words_m)\n",
    "\n",
    "# find all half lives between 600 and 200: \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = df[(df[column] < middle) & (df[column] > lower)] # \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = CLClim3NE1_HLs_Clim3_0_to_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"sort_color\"] = \"lightblue\"\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"column_width\"] = \"4\"\n",
    "words_m2l = f'between {middle} and {lower}: {CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}'\n",
    "print(words_m2l)\n",
    "\n",
    "# find all the half lives between 200 and 0:\n",
    "CLClim3NE1_HLs_Clim3_lower = df[(df[column] <= lower)] # \n",
    "CLClim3NE1_HLs_Clim3_lower = CLClim3NE1_HLs_Clim3_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_lower[\"sort_color\"] = \"blue\"\n",
    "CLClim3NE1_HLs_Clim3_lower[\"column_width\"] = \"1\"\n",
    "words_l = f'less than {lower}: {CLClim3NE1_HLs_Clim3_lower.shape[0]}'\n",
    "print(words_l)\n",
    "\n",
    "\n",
    "# make a new data frame that is more simple\n",
    "# concatenate the data frames together:\n",
    "CLClim3NE1_HLs_Clim3_split_protein_difference = pd.concat([CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_lower], ignore_index=True)\n",
    "data = CLClim3NE1_HLs_Clim3_split_protein_difference[['common_name', column,'sort_color', 'column_width']]\n",
    "\n",
    "# add a new rows to the data: \n",
    "new_rows = [\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}',\n",
    "        column: upper,\n",
    "        'sort_color': 'orange',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_middle.shape[0]}',\n",
    "        column: middle + 0.5,\n",
    "        'sort_color': 'green',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}',\n",
    "        column: lower,\n",
    "        'sort_color': 'lightblue',\n",
    "        'column_width': 4\n",
    "    }\n",
    "]\n",
    "\n",
    "# convert new rows to a DataFrame:\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "data = pd.concat([data, new_rows_df], ignore_index=True)\n",
    "\n",
    "# sort the data\n",
    "data = data.sort_values(by=[column], ascending=False)\n",
    "data.set_index('common_name', inplace=True)\n",
    "\n",
    "\n",
    "# create a color dictionary for the colors:\n",
    "color_dict = {'red': '#fd625e', 'orange': '#f9a825', 'green': 'green', 'lightblue': '#01b8aa', 'blue': '#0d47a1'}\n",
    "\n",
    "# create a size dictionary for the sizes:\n",
    "size_dict = {'red': .1, 'orange': .5, 'green':1,'lightblue': .5, 'blue': .1}\n",
    "\n",
    "upper_len = int(CLClim3NE1_HLs_Clim3_above_upper.shape[0])\n",
    "lower_len = int(CLClim3NE1_HLs_Clim3_lower.shape[0])\n",
    "\n",
    "first_ticks = np.ones(upper_len) * size_dict['red']\n",
    "second_ticks = np.ones(1) * size_dict['orange']\n",
    "third_ticks = np.ones(1) * size_dict['green']\n",
    "fourth_ticks = np.ones(1) * size_dict['lightblue']\n",
    "fifth_ticks = np.ones(lower_len) * size_dict['blue']\n",
    "col_widths = [first_ticks, second_ticks, third_ticks, fourth_ticks, fifth_ticks]\n",
    "col_widths = np.concatenate(col_widths)\n",
    "col_widths\n",
    "\n",
    "# GET THE POSITIONS OF THE BARS\n",
    "# from: https://stackoverflow.com/questions/70477458/how-can-i-plot-bar-plots-with-variable-widths-but-without-gaps-in-python-and-ad\n",
    "a = 0\n",
    "x_positions = []\n",
    "for i in range(len(col_widths)):\n",
    "    if i == 0:\n",
    "        a+=col_widths[i]\n",
    "       \n",
    "        x_positions.append(col_widths[i]/2)\n",
    "        \n",
    "    else:\n",
    "        a += col_widths[i] + 0.05 # adding a gap \n",
    "       \n",
    "        x_positions.append(a - col_widths[i]/2)\n",
    "\n",
    "x_positions = np.array(x_positions)\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "index = data.index\n",
    "column0 = data[column]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20,10),  nrows=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "#axes.bar(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes.set_title(title0, fontsize=18, pad=15, )\n",
    "\n",
    "\n",
    "ticks_to_plot = []\n",
    "for i, val in enumerate(column0):\n",
    "    axes.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "    if data['sort_color'].iloc[i] == 'red':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'blue':\n",
    "        axes.text(x_positions[i], val - 0.35, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'green':\n",
    "        axes.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'orange':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$$\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'lightblue':\n",
    "        axes.text(x_positions[i], val - .5, f\"-$\\\\Delta$$\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "\n",
    "\n",
    "\n",
    "axes.set_ylabel('Log2 fold change in protein counts\\n between the 2025 and 2020 model', fontsize=12, color=\"black\", )\n",
    "axes.set_xlabel('Proteins', fontsize=12, color=\"black\", )\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['bottom'].set_visible(False)\n",
    "axes.set_xticks([])\n",
    "axes.margins(x=0.0)\n",
    "\n",
    "#axes.set_ylim(-600, (lower + 2))  # cant do this here, should only do it when I do not have a shared x axis! \n",
    "\n",
    "# add a legend: \n",
    "#axes.legend(loc='upper right', fontsize=12, frameon=False, markerscale=2)\n",
    "axes.legend(\n",
    "    handles=[\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u, markerfacecolor=color_dict['red'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u2m, markerfacecolor=color_dict['orange'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m, markerfacecolor=color_dict['green'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m2l, markerfacecolor=color_dict['lightblue'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_l, markerfacecolor=color_dict['blue'], markersize=5)\n",
    "    ],\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    markerscale=2\n",
    ")   \n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n"
   ],
   "id": "a54c04c5cf9d7e73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plot the log2 fold change of the protein counts using only the proteins that had a change in half life from their original value\n",
    "prep the data first:"
   ],
   "id": "f025f42c7275be1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_df_of_proteins_with_new_HLs = combined_df.copy()\n",
    "\n",
    "# remove the proteins that have a different half life value between new_half_life and original_half_life:\n",
    "combined_df_of_proteins_with_new_HLs = combined_df_of_proteins_with_new_HLs[combined_df_of_proteins_with_new_HLs['HL_difference'] != 0] # should add up to 2675, as I believe that is how many were reassigned to Gupta et al. 2024 data! \n",
    "\n",
    "combined_df_of_proteins_with_new_HLs"
   ],
   "id": "3d5a1f49d4e8d040",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the dataframe to plot: \n",
    "df = combined_df_of_proteins_with_new_HLs.copy()\n",
    "\n",
    "# define column to plot: \n",
    "column = 'PC_log2_fold_change'\n",
    "\n",
    "# define bounds for changes\n",
    "upper = 3\n",
    "middle = 0\n",
    "lower = -3\n",
    "\n",
    "# define the name of the file: \n",
    "out_pth = f\"out/figures/PDR_UPDATE_MERGE/F2/change_in_half_life_histograms/log2_fold_change_in_protein_count_values_for_proteins_with_new_HL_values_bounds[{lower},{middle},{upper}]_{current_sequence}_{CLNE_sequence}.png\"\n",
    "\n",
    "# define the title of the plot:\n",
    "title0 = f'Log2 fold change of the average protein counts \\n between the 2020 and 2025 model for proteins\\n with new half life values (n={df.shape[0]})'\n",
    "\n",
    "\n",
    "# find all of the half lives that are greater than 800:\n",
    "CLClim3NE1_HLs_Clim3_above_upper = df[df[column] > upper] # \n",
    "CLClim3NE1_HLs_Clim3_above_upper = CLClim3NE1_HLs_Clim3_above_upper.copy()\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"sort_color\"] = \"red\"\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"column_width\"] = \"1\"\n",
    "words_u = f'greater than {upper}: {CLClim3NE1_HLs_Clim3_above_upper.shape[0]}'\n",
    "print(words_u)\n",
    "\n",
    "# find all the half lives between 800 and 0: \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = df[(df[column] <= upper) & (df[column] > middle)] # \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = CLClim3NE1_HLs_Clim3_upper_to_zero.copy()\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"sort_color\"] = \"orange\"\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"column_width\"] = \"4\"\n",
    "words_u2m = f'between {upper} and {middle}: {CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}'\n",
    "print(words_u2m)\n",
    "\n",
    "CLClim3NE1_HLs_Clim3_middle = df[df[column] == middle ] #\n",
    "CLClim3NE1_HLs_Clim3_middle = CLClim3NE1_HLs_Clim3_middle.copy()\n",
    "CLClim3NE1_HLs_Clim3_middle[\"sort_color\"] = \"green\"\n",
    "CLClim3NE1_HLs_Clim3_middle[\"column_width\"] = \"4\"\n",
    "words_m = f'exactly {middle}: {CLClim3NE1_HLs_Clim3_middle.shape[0]}'\n",
    "print(words_m)\n",
    "\n",
    "# find all half lives between 600 and 200: \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = df[(df[column] < middle) & (df[column] > lower)] # \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = CLClim3NE1_HLs_Clim3_0_to_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"sort_color\"] = \"lightblue\"\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"column_width\"] = \"4\"\n",
    "words_m2l = f'between {middle} and {lower}: {CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}'\n",
    "print(words_m2l)\n",
    "\n",
    "# find all the half lives between 200 and 0:\n",
    "CLClim3NE1_HLs_Clim3_lower = df[(df[column] <= lower)] # \n",
    "CLClim3NE1_HLs_Clim3_lower = CLClim3NE1_HLs_Clim3_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_lower[\"sort_color\"] = \"blue\"\n",
    "CLClim3NE1_HLs_Clim3_lower[\"column_width\"] = \"1\"\n",
    "words_l = f'less than {lower}: {CLClim3NE1_HLs_Clim3_lower.shape[0]}'\n",
    "print(words_l)\n",
    "\n",
    "\n",
    "# make a new data frame that is more simple\n",
    "# concatenate the data frames together:\n",
    "CLClim3NE1_HLs_Clim3_split_protein_difference = pd.concat([CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_lower], ignore_index=True)\n",
    "data = CLClim3NE1_HLs_Clim3_split_protein_difference[['common_name', column,'sort_color', 'column_width']]\n",
    "\n",
    "# add a new rows to the data: \n",
    "new_rows = [\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}',\n",
    "        column: upper,\n",
    "        'sort_color': 'orange',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_middle.shape[0]}',\n",
    "        column: middle + 0.5,\n",
    "        'sort_color': 'green',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}',\n",
    "        column: lower,\n",
    "        'sort_color': 'lightblue',\n",
    "        'column_width': 4\n",
    "    }\n",
    "]\n",
    "\n",
    "# convert new rows to a DataFrame:\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "data = pd.concat([data, new_rows_df], ignore_index=True)\n",
    "\n",
    "# sort the data\n",
    "data = data.sort_values(by=[column], ascending=False)\n",
    "data.set_index('common_name', inplace=True)\n",
    "\n",
    "\n",
    "# create a color dictionary for the colors:\n",
    "color_dict = {'red': '#fd625e', 'orange': '#f9a825', 'green': 'green', 'lightblue': '#01b8aa', 'blue': '#0d47a1'}\n",
    "\n",
    "# create a size dictionary for the sizes:\n",
    "size_dict = {'red': .1, 'orange': .5, 'green':1,'lightblue': .5, 'blue': .1}\n",
    "\n",
    "upper_len = int(CLClim3NE1_HLs_Clim3_above_upper.shape[0])\n",
    "lower_len = int(CLClim3NE1_HLs_Clim3_lower.shape[0])\n",
    "\n",
    "first_ticks = np.ones(upper_len) * size_dict['red']\n",
    "second_ticks = np.ones(1) * size_dict['orange']\n",
    "third_ticks = np.ones(1) * size_dict['green']\n",
    "fourth_ticks = np.ones(1) * size_dict['lightblue']\n",
    "fifth_ticks = np.ones(lower_len) * size_dict['blue']\n",
    "col_widths = [first_ticks, second_ticks, third_ticks, fourth_ticks, fifth_ticks]\n",
    "col_widths = np.concatenate(col_widths)\n",
    "col_widths\n",
    "\n",
    "# GET THE POSITIONS OF THE BARS\n",
    "# from: https://stackoverflow.com/questions/70477458/how-can-i-plot-bar-plots-with-variable-widths-but-without-gaps-in-python-and-ad\n",
    "a = 0\n",
    "x_positions = []\n",
    "for i in range(len(col_widths)):\n",
    "    if i == 0:\n",
    "        a+=col_widths[i]\n",
    "       \n",
    "        x_positions.append(col_widths[i]/2)\n",
    "        \n",
    "    else:\n",
    "        a += col_widths[i] + 0.05 # adding a gap \n",
    "       \n",
    "        x_positions.append(a - col_widths[i]/2)\n",
    "\n",
    "x_positions = np.array(x_positions)\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "index = data.index\n",
    "column0 = data[column]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20,10),  nrows=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "#axes.bar(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes.set_title(title0, fontsize=18, pad=15, )\n",
    "\n",
    "\n",
    "ticks_to_plot = []\n",
    "for i, val in enumerate(column0):\n",
    "    axes.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "    if data['sort_color'].iloc[i] == 'red':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'blue':\n",
    "        axes.text(x_positions[i], val - 0.35, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'green':\n",
    "        axes.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'orange':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$$\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'lightblue':\n",
    "        axes.text(x_positions[i], val - .5, f\"-$\\\\Delta$$\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "\n",
    "\n",
    "\n",
    "axes.set_ylabel('Log2 fold change in protein counts\\n between the 2025 and 2020 model', fontsize=12, color=\"black\", )\n",
    "axes.set_xlabel('Proteins', fontsize=12, color=\"black\", )\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['bottom'].set_visible(False)\n",
    "axes.set_xticks([])\n",
    "axes.margins(x=0.0)\n",
    "\n",
    "#axes.set_ylim(-600, (lower + 2))  # cant do this here, should only do it when I do not have a shared x axis! \n",
    "\n",
    "# add a legend: \n",
    "#axes.legend(loc='upper right', fontsize=12, frameon=False, markerscale=2)\n",
    "axes.legend(\n",
    "    handles=[\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u, markerfacecolor=color_dict['red'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u2m, markerfacecolor=color_dict['orange'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m, markerfacecolor=color_dict['green'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m2l, markerfacecolor=color_dict['lightblue'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_l, markerfacecolor=color_dict['blue'], markersize=5)\n",
    "    ],\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    markerscale=2\n",
    ")   \n",
    "\n",
    "\n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n"
   ],
   "id": "1a45a4430efddb8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plot the log2 fold change of the protein counts using only the proteins that had no change in half life from their original value\n",
    "Prep the data: \n"
   ],
   "id": "94692615e04cb0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_df_of_proteins_with_same_HLs = combined_df.copy()\n",
    "\n",
    "# remove the proteins that have a different half life value between new_half_life and original_half_life:\n",
    "combined_df_of_proteins_with_same_HLs = combined_df_of_proteins_with_same_HLs[combined_df_of_proteins_with_same_HLs['HL_difference'] == 0] # should add up to 2675, as I believe that is how many were reassigned to Gupta et al. 2024 data! \n",
    "\n",
    "combined_df_of_proteins_with_same_HLs\n"
   ],
   "id": "d8e3af84494dc13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the data to use: \n",
    "df = combined_df_of_proteins_with_same_HLs.copy()\n",
    "\n",
    "# define column to plot: \n",
    "column = 'PC_log2_fold_change'\n",
    "\n",
    "# define bounds for changes\n",
    "upper = 4\n",
    "middle = 0\n",
    "lower = -4\n",
    "\n",
    "# define the name of the file: \n",
    "out_pth = f\"out/figures/PDR_UPDATE_MERGE/F2/change_in_half_life_histograms/log2_fold_change_in_protein_count_values_for_proteins_with_no_change_in_HL_bounds[{lower},{middle},{upper}]_{current_sequence}_{CLNE_sequence}.png\"\n",
    "\n",
    "# define the title of the plot:\n",
    "title0 = f'Log2 fold change of the average protein counts \\n between the 2020 and 2025 model for proteins with \\nthe same half life in both models (n={df.shape[0]})'\n",
    "\n",
    "# find all of the half lives that are greater than 800:\n",
    "CLClim3NE1_HLs_Clim3_above_upper = df[df[column] > upper] # \n",
    "CLClim3NE1_HLs_Clim3_above_upper = CLClim3NE1_HLs_Clim3_above_upper.copy()\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"sort_color\"] = \"red\"\n",
    "CLClim3NE1_HLs_Clim3_above_upper[\"column_width\"] = \"1\"\n",
    "words_u = f'greater than {upper}: {CLClim3NE1_HLs_Clim3_above_upper.shape[0]}'\n",
    "print(words_u)\n",
    "\n",
    "# find all the half lives between 800 and 0: \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = df[(df[column] <= upper) & (df[column] > middle)] # \n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero = CLClim3NE1_HLs_Clim3_upper_to_zero.copy()\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"sort_color\"] = \"orange\"\n",
    "CLClim3NE1_HLs_Clim3_upper_to_zero[\"column_width\"] = \"4\"\n",
    "words_u2m = f'between {upper} and {middle}: {CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}'\n",
    "print(words_u2m)\n",
    "\n",
    "CLClim3NE1_HLs_Clim3_middle = df[df[column] == middle ] #\n",
    "CLClim3NE1_HLs_Clim3_middle = CLClim3NE1_HLs_Clim3_middle.copy()\n",
    "CLClim3NE1_HLs_Clim3_middle[\"sort_color\"] = \"green\"\n",
    "CLClim3NE1_HLs_Clim3_middle[\"column_width\"] = \"4\"\n",
    "words_m = f'exactly {middle}: {CLClim3NE1_HLs_Clim3_middle.shape[0]}'\n",
    "print(words_m)\n",
    "\n",
    "# find all half lives between 600 and 200: \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = df[(df[column] < middle) & (df[column] > lower)] # \n",
    "CLClim3NE1_HLs_Clim3_0_to_lower = CLClim3NE1_HLs_Clim3_0_to_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"sort_color\"] = \"lightblue\"\n",
    "CLClim3NE1_HLs_Clim3_0_to_lower[\"column_width\"] = \"4\"\n",
    "words_m2l = f'between {middle} and {lower}: {CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}'\n",
    "print(words_m2l)\n",
    "\n",
    "# find all the half lives between 200 and 0:\n",
    "CLClim3NE1_HLs_Clim3_lower = df[(df[column] <= lower)] # \n",
    "CLClim3NE1_HLs_Clim3_lower = CLClim3NE1_HLs_Clim3_lower.copy()\n",
    "CLClim3NE1_HLs_Clim3_lower[\"sort_color\"] = \"blue\"\n",
    "CLClim3NE1_HLs_Clim3_lower[\"column_width\"] = \"1\"\n",
    "words_l = f'less than {lower}: {CLClim3NE1_HLs_Clim3_lower.shape[0]}'\n",
    "print(words_l)\n",
    "\n",
    "\n",
    "# make a new data frame that is more simple\n",
    "# concatenate the data frames together:\n",
    "CLClim3NE1_HLs_Clim3_split_protein_difference = pd.concat([CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_lower], ignore_index=True)\n",
    "data = CLClim3NE1_HLs_Clim3_split_protein_difference[['common_name', column,'sort_color', 'column_width']]\n",
    "\n",
    "# add a new rows to the data: \n",
    "new_rows = [\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}',\n",
    "        column: upper,\n",
    "        'sort_color': 'orange',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_middle.shape[0]}',\n",
    "        column: middle + 0.5,\n",
    "        'sort_color': 'green',\n",
    "        'column_width': 4\n",
    "    },\n",
    "    {\n",
    "        'common_name': f'n={CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}',\n",
    "        column: lower,\n",
    "        'sort_color': 'lightblue',\n",
    "        'column_width': 4\n",
    "    }\n",
    "]\n",
    "\n",
    "# convert new rows to a DataFrame:\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "data = pd.concat([data, new_rows_df], ignore_index=True)\n",
    "\n",
    "# sort the data\n",
    "data = data.sort_values(by=[column], ascending=False)\n",
    "data.set_index('common_name', inplace=True)\n",
    "\n",
    "\n",
    "# create a color dictionary for the colors:\n",
    "color_dict = {'red': '#fd625e', 'orange': '#f9a825', 'green': 'green', 'lightblue': '#01b8aa', 'blue': '#0d47a1'}\n",
    "\n",
    "# create a size dictionary for the sizes:\n",
    "size_dict = {'red': .1, 'orange': .5, 'green':1,'lightblue': .5, 'blue': .1}\n",
    "\n",
    "upper_len = int(CLClim3NE1_HLs_Clim3_above_upper.shape[0])\n",
    "lower_len = int(CLClim3NE1_HLs_Clim3_lower.shape[0])\n",
    "\n",
    "first_ticks = np.ones(upper_len) * size_dict['red']\n",
    "second_ticks = np.ones(1) * size_dict['orange']\n",
    "third_ticks = np.ones(1) * size_dict['green']\n",
    "fourth_ticks = np.ones(1) * size_dict['lightblue']\n",
    "fifth_ticks = np.ones(lower_len) * size_dict['blue']\n",
    "col_widths = [first_ticks, second_ticks, third_ticks, fourth_ticks, fifth_ticks]\n",
    "col_widths = np.concatenate(col_widths)\n",
    "\n",
    "# GET THE POSITIONS OF THE BARS\n",
    "# from: https://stackoverflow.com/questions/70477458/how-can-i-plot-bar-plots-with-variable-widths-but-without-gaps-in-python-and-ad\n",
    "a = 0\n",
    "x_positions = []\n",
    "for i in range(len(col_widths)):\n",
    "    if i == 0:\n",
    "        a+=col_widths[i]\n",
    "       \n",
    "        x_positions.append(col_widths[i]/2)\n",
    "        \n",
    "    else:\n",
    "        a += col_widths[i] + 0.05 # adding a gap \n",
    "       \n",
    "        x_positions.append(a - col_widths[i]/2)\n",
    "\n",
    "x_positions = np.array(x_positions)\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "index = data.index\n",
    "column0 = data[column]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20,10),  nrows=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "#axes.bar(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes.set_title(title0, fontsize=18, pad=15, )\n",
    "\n",
    "\n",
    "ticks_to_plot = []\n",
    "for i, val in enumerate(column0):\n",
    "    axes.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "    if data['sort_color'].iloc[i] == 'red':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'blue':\n",
    "        axes.text(x_positions[i], val - 0.35, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "    if data['sort_color'].iloc[i] == 'green':\n",
    "        axes.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'orange':\n",
    "        axes.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$$\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    if data['sort_color'].iloc[i] == 'lightblue':\n",
    "        axes.text(x_positions[i], val - .5, f\"-$\\\\Delta$$\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "        axes.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "\n",
    "\n",
    "\n",
    "axes.set_ylabel('Log2 fold change in protein counts\\n between the 2025 and 2020 model', fontsize=12, color=\"black\", )\n",
    "axes.set_xlabel('Proteins', fontsize=12, color=\"black\", )\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['bottom'].set_visible(False)\n",
    "axes.set_xticks([])\n",
    "axes.margins(x=0.0)\n",
    "\n",
    "#axes.set_ylim(-600, (lower + 2))  # cant do this here, should only do it when I do not have a shared x axis! \n",
    "\n",
    "# add a legend: \n",
    "#axes.legend(loc='upper right', fontsize=12, frameon=False, markerscale=2)\n",
    "axes.legend(\n",
    "    handles=[\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u, markerfacecolor=color_dict['red'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_u2m, markerfacecolor=color_dict['orange'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m, markerfacecolor=color_dict['green'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_m2l, markerfacecolor=color_dict['lightblue'], markersize=5),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=words_l, markerfacecolor=color_dict['blue'], markersize=5)\n",
    "    ],\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    markerscale=2\n",
    ")   \n",
    "\n",
    "\n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n"
   ],
   "id": "a6a954ac58a76f80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c074ec983bfbf1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Matrix of the changes",
   "id": "ce55f33bb9c8c442"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Specify what to plot:",
   "id": "432f905e9b67baa0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# USER INPUTS:\n",
    "\n",
    "# define bounds for changes in half lives:\n",
    "HL_upper = 7\n",
    "HL_middle = 0\n",
    "HL_lower = -4\n",
    "\n",
    "# define bounds for changes in protein counts:\n",
    "PC_upper = 4\n",
    "PC_middle = 0\n",
    "PC_lower = -4\n",
    "\n",
    "# define bounds for changes in the histogram\n",
    "upper_histogram = None\n",
    "lower_histogram = None\n",
    "bins_histogram = 200\n",
    "\n",
    "print(\"User inputs specified. now run the code in the next block!\")"
   ],
   "id": "f099424ad8eddaf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# todo: edit the functions to take in axes as an input (since it is currenlty not, which could cause issues later) \n",
    "# todo edit this to deal with inputs less than 1 since that messes up the order) \n",
    "\n",
    "# define the name of the file: \n",
    "out_pth_root = f\"out/figures/{branch_name}/F2/matrix_plots/{current_sequence}_vs_{CLNE_sequence}/\"\n",
    "if not os.path.exists(out_pth_root):\n",
    "    os.makedirs(out_pth_root)\n",
    "    \n",
    "# generate the first output file path:\n",
    "specific_title1 = f\"HL_matrix_HL_bounds[{HL_lower},{HL_middle},{HL_upper}]_PC_bounds[{PC_lower},{PC_middle},{PC_upper}]_histogram_xbounds[{upper_histogram},{lower_histogram}]_xbins[{bins_histogram}]_{current_sequence}_vs_{CLNE_sequence}.png\"\n",
    "out_pth_bar_graph = out_pth_root + specific_title1\n",
    "\n",
    "specific_title2 = f\"counts_validation_matrix_HL_bounds[{HL_lower},{HL_middle},{HL_upper}]_PC_bounds[{PC_lower},{PC_middle},{PC_upper}]_{current_sequence}_{CLNE_sequence}.png\"\n",
    "out_pth_validation_matrix = out_pth_root + specific_title2\n",
    "\n",
    "# GENERATE THE BAR, HISTOGRAM, AND MATRIX PLOTS\n",
    "# define the data to use: \n",
    "df = combined_df.copy()\n",
    "\n",
    "# define columns to plot: \n",
    "column0 = 'HL_log2_fold_change'\n",
    "column1 = 'PC_log2_fold_change'\n",
    "\n",
    "# define column to plot in the histogram:\n",
    "column_histogram = 'PC_log2_fold_change'\n",
    "\n",
    "# define the title of the plot:\n",
    "title0 = f'$Log_{2}$ fold $\\\\Delta$ in the half life value between\\n the 2020 and 2025 model (n={df.shape[0]})'\n",
    "title1 = f'$Log_{2}$ fold $\\\\Delta$ in the average protein counts between\\n the 2020 and 2025 model (n={df.shape[0]})'\n",
    "\n",
    "\n",
    "# END USER INPUTS\n",
    "def r2_score_y_equals_x(y_true, y_pred):\n",
    "    # Calculate the squared differences from the predicted line y=x\n",
    "    residuals = y_true - y_pred\n",
    "    ss_res = np.sum(residuals ** 2)  # Residual Sum of Squares\n",
    "\n",
    "    # Calculate the total sum of squares\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # Total Sum of Squares\n",
    "\n",
    "    # Calculate R\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "\n",
    "def obtain_data(df, column, upper, middle, lower):\n",
    "    print(column)\n",
    "    print(df[column].describe())\n",
    "    # find all of the half lives that are greater than 800:\n",
    "    CLClim3NE1_HLs_Clim3_above_upper = df[df[column] > upper] # \n",
    "    CLClim3NE1_HLs_Clim3_above_upper = CLClim3NE1_HLs_Clim3_above_upper.copy()\n",
    "    CLClim3NE1_HLs_Clim3_above_upper[\"sort_color\"] = \"red\"\n",
    "    CLClim3NE1_HLs_Clim3_above_upper[\"column_width\"] = \"1\"\n",
    "    words_u = f'greater than {upper}: {CLClim3NE1_HLs_Clim3_above_upper.shape[0]}'\n",
    "    print(words_u)\n",
    "    \n",
    "    # find all the half lives between 800 and 0: \n",
    "    CLClim3NE1_HLs_Clim3_upper_to_zero = df[(df[column] <= upper) & (df[column] > middle)] # \n",
    "    CLClim3NE1_HLs_Clim3_upper_to_zero = CLClim3NE1_HLs_Clim3_upper_to_zero.copy()\n",
    "    CLClim3NE1_HLs_Clim3_upper_to_zero[\"sort_color\"] = \"orange\"\n",
    "    CLClim3NE1_HLs_Clim3_upper_to_zero[\"column_width\"] = \"4\"\n",
    "    words_u2m = f'between {upper} and {middle}: {CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}'\n",
    "    print(words_u2m)\n",
    "    \n",
    "    CLClim3NE1_HLs_Clim3_middle = df[df[column] == middle ] #\n",
    "    CLClim3NE1_HLs_Clim3_middle = CLClim3NE1_HLs_Clim3_middle.copy()\n",
    "    CLClim3NE1_HLs_Clim3_middle[\"sort_color\"] = \"green\"\n",
    "    CLClim3NE1_HLs_Clim3_middle[\"column_width\"] = \"4\"\n",
    "    words_m = f'exactly {middle}: {CLClim3NE1_HLs_Clim3_middle.shape[0]}'\n",
    "    print(words_m)\n",
    "    \n",
    "    # find all half lives between 600 and 200: \n",
    "    CLClim3NE1_HLs_Clim3_0_to_lower = df[(df[column] < middle) & (df[column] >= lower)] # \n",
    "    CLClim3NE1_HLs_Clim3_0_to_lower = CLClim3NE1_HLs_Clim3_0_to_lower.copy()\n",
    "    CLClim3NE1_HLs_Clim3_0_to_lower[\"sort_color\"] = \"lightblue\"\n",
    "    CLClim3NE1_HLs_Clim3_0_to_lower[\"column_width\"] = \"4\"\n",
    "    words_m2l = f'between {middle} and {lower}: {CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}'\n",
    "    print(words_m2l)\n",
    "    \n",
    "    # find all the half lives between 200 and 0:\n",
    "    CLClim3NE1_HLs_Clim3_lower = df[(df[column] < lower)] # \n",
    "    CLClim3NE1_HLs_Clim3_lower = CLClim3NE1_HLs_Clim3_lower.copy()\n",
    "    CLClim3NE1_HLs_Clim3_lower[\"sort_color\"] = \"blue\"\n",
    "    CLClim3NE1_HLs_Clim3_lower[\"column_width\"] = \"1\"\n",
    "    words_l = f'less than {lower}: {CLClim3NE1_HLs_Clim3_lower.shape[0]}'\n",
    "    print(words_l)\n",
    "\n",
    "    return(CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_upper_to_zero, CLClim3NE1_HLs_Clim3_middle, CLClim3NE1_HLs_Clim3_0_to_lower, CLClim3NE1_HLs_Clim3_lower, words_u, words_u2m, words_m, words_m2l, words_l)\n",
    "\n",
    "\n",
    "\n",
    "def clean_data(column, CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_upper_to_zero, CLClim3NE1_HLs_Clim3_middle, CLClim3NE1_HLs_Clim3_0_to_lower, CLClim3NE1_HLs_Clim3_lower, upper, middle, lower):\n",
    "    # make a new data frame that is more simple\n",
    "    # concatenate the data frames together:\n",
    "    CLClim3NE1_HLs_Clim3_split_protein_difference = pd.concat([CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_lower], ignore_index=True)\n",
    "    data = CLClim3NE1_HLs_Clim3_split_protein_difference[['common_name', column,'sort_color', 'column_width']]\n",
    "    \n",
    "    # add a new rows to the data: \n",
    "    new_rows = [\n",
    "        {\n",
    "            'common_name': f'n={CLClim3NE1_HLs_Clim3_upper_to_zero.shape[0]}',\n",
    "            column: upper, \n",
    "            'sort_color': 'orange',\n",
    "            'column_width': 4\n",
    "        },\n",
    "        {\n",
    "            'common_name': f'n={CLClim3NE1_HLs_Clim3_middle.shape[0]}',\n",
    "            column: middle + 0.5,\n",
    "            'sort_color': 'green',\n",
    "            'column_width': 4\n",
    "        },\n",
    "        {\n",
    "            'common_name': f'n={CLClim3NE1_HLs_Clim3_0_to_lower.shape[0]}',\n",
    "            column: lower,\n",
    "            'sort_color': 'lightblue',\n",
    "            'column_width': 4\n",
    "        }\n",
    "    ]\n",
    "    # NOTE:  I THINK THE OVERLAP ISSUE OCCURS WHEN THE GRAPH ABOVE THIS ONE OVERRIDES THESE FUNCTIONS! bc when I restart the code I dont get the issue anymore with the weird overlap \n",
    "    \n",
    "    # convert new rows to a DataFrame:\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    data = pd.concat([data, new_rows_df], ignore_index=True)\n",
    "    \n",
    "    # sort the data\n",
    "    data = data.sort_values(by=[column], ascending=False) # this is an issue I think?\n",
    "    data.set_index('common_name', inplace=True)\n",
    "\n",
    "    # create a color dictionary for the colors:\n",
    "    color_dict = {'red': '#fd625e', 'orange': '#f9a825', 'green': 'green', 'lightblue': '#01b8aa', 'blue': '#0d47a1'}\n",
    "    \n",
    "    # create a size dictionary for the sizes:\n",
    "    size_dict = {'red': .1, 'orange': .5, 'green':1,'lightblue': .5, 'blue': .1}\n",
    "    \n",
    "    \n",
    "    upper_len = int(CLClim3NE1_HLs_Clim3_above_upper.shape[0]) # is the fact that I use int here an issue? will it auto round when it should not?\n",
    "    lower_len = int(CLClim3NE1_HLs_Clim3_lower.shape[0])\n",
    "    \n",
    "    first_ticks = np.ones(upper_len) * size_dict['red']\n",
    "    second_ticks = np.ones(1) * size_dict['orange']\n",
    "    third_ticks = np.ones(1) * size_dict['green']\n",
    "    fourth_ticks = np.ones(1) * size_dict['lightblue']\n",
    "    fifth_ticks = np.ones(lower_len) * size_dict['blue']\n",
    "    col_widths = [first_ticks, second_ticks, third_ticks, fourth_ticks, fifth_ticks]\n",
    "    col_widths = np.concatenate(col_widths)\n",
    "    \n",
    "    # GET THE POSITIONS OF THE BARS\n",
    "    # from: https://stackoverflow.com/questions/70477458/how-can-i-plot-bar-plots-with-variable-widths-but-without-gaps-in-python-and-ad\n",
    "    a = 0\n",
    "    x_positions = []\n",
    "    for i in range(len(col_widths)):\n",
    "        if i == 0:\n",
    "            a+=col_widths[i]\n",
    "            x_positions.append(col_widths[i]/2)\n",
    "            \n",
    "        else:\n",
    "            a += col_widths[i] + 0.05 # adding a gap \n",
    "            x_positions.append(a - col_widths[i]/2)\n",
    "    \n",
    "    x_positions = np.array(x_positions)\n",
    "    \n",
    "    return data, x_positions, col_widths, color_dict, size_dict\n",
    "\n",
    "print(x_positions)\n",
    "\n",
    "\n",
    "def make_subplot(row, col, df, column, variable, upper, middle, lower, title,):\n",
    "    CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_upper_to_zero, CLClim3NE1_HLs_Clim3_middle, CLClim3NE1_HLs_Clim3_0_to_lower, CLClim3NE1_HLs_Clim3_lower, words_u, words_u2m, words_m, words_m2l, words_l = obtain_data(df, column, upper, middle, lower)\n",
    "    \n",
    "    data, x_positions, col_widths, color_dict, size_dict = clean_data(column, CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_upper_to_zero, CLClim3NE1_HLs_Clim3_middle, CLClim3NE1_HLs_Clim3_0_to_lower, CLClim3NE1_HLs_Clim3_lower, upper, middle, lower)\n",
    "    \n",
    "    # begin the plot:\n",
    "    index = data.index\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # use the if row statement to tune the values added to the val varioable for each plot (as these may need to change depending on the bounds): \n",
    "    if column == 'HL_log2_fold_change':\n",
    "        for i, val in enumerate(data[column]):\n",
    "            ax.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "            if data['sort_color'].iloc[i] == 'red':\n",
    "                ax.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 1.4, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "            if data['sort_color'].iloc[i] == 'blue':\n",
    "                ax.text(x_positions[i], val - 0.75, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "            if data['sort_color'].iloc[i] == 'green':\n",
    "                ax.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "            if data['sort_color'].iloc[i] == 'orange':\n",
    "                ax.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$$\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "            if data['sort_color'].iloc[i] == 'lightblue':\n",
    "                ax.text(x_positions[i], val - .7, f\"-$\\\\Delta$$\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                \n",
    "    else:\n",
    "        for i, val in enumerate(data[column]):\n",
    "            ax.bar(x_positions[i], val, color=color_dict[data['sort_color'].iloc[i]], width=size_dict[data['sort_color'].iloc[i]])\n",
    "            if data['sort_color'].iloc[i] == 'red':\n",
    "                ax.text(x_positions[i], val + 0.25, f\"+{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 1, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "            if data['sort_color'].iloc[i] == 'blue':\n",
    "                ax.text(x_positions[i], val - 0.55, f\"{val:.1f}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=45, )\n",
    "            if data['sort_color'].iloc[i] == 'green':\n",
    "                ax.text(x_positions[i], val + 0.5, f\"{middle}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "            if data['sort_color'].iloc[i] == 'orange':\n",
    "                ax.text(x_positions[i], val + 0.25, f\"+$\\\\Delta$ $\\\\in$({middle},{upper}]\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 - 0.8, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "            if data['sort_color'].iloc[i] == 'lightblue':\n",
    "                ax.text(x_positions[i], val - .5, f\"-$\\\\Delta$ $\\\\in$[{lower},{middle})\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "                ax.text(x_positions[i], 0 + 0.25, f\"{index[i]}\", ha='center', va='bottom', fontsize=10, rotation=0, )\n",
    "    \n",
    "    # plot specifications:\n",
    "    ax.set_title(title, fontsize=15, pad=15, )\n",
    "    ax.set_ylabel(f'$Log_{2}$ fold $\\\\Delta$ in {variable}\\n between the 2025 and 2020 model', fontsize=12, color=\"black\", )\n",
    "    ax.set_xlabel('Proteins', fontsize=12, color=\"black\", )\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.margins(x=0.0)\n",
    "\n",
    "\n",
    "    ax.legend(handles=[\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label=words_u, markerfacecolor=color_dict['red'], markersize=5),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label=words_u2m, markerfacecolor=color_dict['orange'], markersize=5),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label=words_m, markerfacecolor=color_dict['green'], markersize=5),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label=words_m2l, markerfacecolor=color_dict['lightblue'], markersize=5),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label=words_l, markerfacecolor=color_dict['blue'], markersize=5)],\n",
    "        loc='upper right', fontsize=12, frameon=False, markerscale=2)   \n",
    "\n",
    "\n",
    "\n",
    "def find_inputs(input_df, u_output_df, u2m_output_df, m_output_df, m2l_output_df, l_output_df):\n",
    "    #find where the common names in the input_df show up in the output df(s)\n",
    "    in_u_output_df = input_df[input_df['common_name'].isin(u_output_df['common_name'])]\n",
    "    in_u2m_output_df = input_df[input_df['common_name'].isin(u2m_output_df['common_name'])]\n",
    "    #print(in_u2m_output_df)\n",
    "    in_m_output_df = input_df[input_df['common_name'].isin(m_output_df['common_name'])]\n",
    "    in_m2l_output_df = input_df[input_df['common_name'].isin(m2l_output_df['common_name'])]\n",
    "    in_l_output_df = input_df[input_df['common_name'].isin(l_output_df['common_name'])]\n",
    "    \n",
    "    # find the number of common names in each output df:\n",
    "    u_count = in_u_output_df.shape[0]\n",
    "    u2m_count = in_u2m_output_df.shape[0]\n",
    "    m_count = in_m_output_df.shape[0]\n",
    "    m2l_count = in_m2l_output_df.shape[0]\n",
    "    l_count = in_l_output_df.shape[0]\n",
    "    \n",
    "    \n",
    "    # create a dictionary of the counts:\n",
    "    counts = {\n",
    "        'u': u_count,\n",
    "        'u2m': u2m_count,\n",
    "        'm': m_count,\n",
    "        'm2l': m2l_count,\n",
    "        'l': l_count}\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def make_histogram(row, col, df, column, bins, upper=None, lower=None):\n",
    "    # make a histogram of the log2 fold change for protein counts: \n",
    "    ax = axes[row, col]\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # define the data to use:    \n",
    "    combined_df_of_proteins_with_same_HLs = df[df['HL_difference'] == 0]\n",
    "    combined_df_of_proteins_with_new_HLs = df[df['HL_difference'] != 0]\n",
    "    df1 = combined_df_of_proteins_with_same_HLs.copy()\n",
    "    df2 = combined_df_of_proteins_with_new_HLs.copy()\n",
    "    \n",
    "    # define the title of the plot:\n",
    "    if upper == None and lower == None:\n",
    "        title = f'Histogram of the log2 fold change in protein counts between \\nthe 2025 and 2020 model with {bins} bins'\n",
    "    else:\n",
    "        # take out the values that are above the upper bound:\n",
    "        df1 = df1[df1[column] < upper]\n",
    "        df2 = df2[df2[column] < upper]\n",
    "        # take out the values that are below the lower bound:\n",
    "        df1 = df1[df1[column] > lower]\n",
    "        df2 = df2[df2[column] > lower]\n",
    "        # get the size of the data:\n",
    "        num = df1.shape[0] + df2.shape[0]\n",
    "        title = f'Histogram of the log2 fold change in protein counts between \\nthe 2025 and 2020 model (between {lower} and {upper}, n={num})\\nwith {bins} bins'\n",
    "        \n",
    "    \n",
    "    # make the histogram:\n",
    "    sns.histplot(df1[column],  bins=bins, color='green', alpha=0.3, kde=True, element='step',\n",
    "             label=f'proteins retaining their original HLs,\\n n={df1.shape[0]}', edgecolor='green', linewidth=.1, ax=ax)\n",
    "    sns.histplot(df2[column], bins=bins,  color='pink', alpha=0.5, kde=True, element='step',\n",
    "             label=f'proteins reassigned to new HLs,\\n n={df2.shape[0]}', edgecolor='pink', linewidth=.1, ax=ax)\n",
    "    \n",
    "    ax.set_title(title, fontsize=15, pad=15, )\n",
    "    ax.set_xlabel(f'$Log_{2}$ fold $\\\\Delta$ in protein counts', fontsize=12, color=\"black\", )\n",
    "    ax.set_ylabel('# of proteins', fontsize=12, color=\"black\", )\n",
    "    ax.legend(loc='upper right', fontsize=8, frameon=False, markerscale=2)\n",
    "    \n",
    "\n",
    "\n",
    "# next, make a confusion matrix of the data:\n",
    "def make_matrix(row, col, df, column0, column1, upper_HL, middle_HL, lower_HL, upper_PC, middle_PC, lower_PC):\n",
    "    # make a confusion matrix of the data:\n",
    "    HL_u, HL_u2m, HL_m, HL_m2l, HL_l, words_u, words_u2m, words_m, words_m2l, words_l = obtain_data(df, column0, upper_HL, middle_HL, lower_HL)\n",
    "    \n",
    "    PC_u, PC_u2m, PC_m, PC_m2l, PC_l, words_u, words_u2m, words_m, words_m2l, words_l = obtain_data(df, column1, upper_PC, middle_PC, lower_PC)\n",
    "    \n",
    "    # find the counts of the common names in each output df:\n",
    "    counts1 = find_inputs(HL_u, PC_u, PC_u2m, PC_m, PC_m2l, PC_l)\n",
    "    counts2 = find_inputs(HL_u2m, PC_u, PC_u2m, PC_m, PC_m2l, PC_l)\n",
    "    counts3 = find_inputs(HL_m, PC_u, PC_u2m, PC_m, PC_m2l, PC_l)\n",
    "    counts4 = find_inputs(HL_m2l, PC_u, PC_u2m, PC_m, PC_m2l, PC_l)\n",
    "    counts5 = find_inputs(HL_l, PC_u, PC_u2m, PC_m, PC_m2l, PC_l)\n",
    "    \n",
    "    # make the matrix: \n",
    "    matrix_df = pd.DataFrame([\n",
    "    [counts1['u'], counts1['u2m'], counts1['m'], counts1['m2l'], counts1['l']],\n",
    "    [counts2['u'], counts2['u2m'], counts2['m'], counts2['m2l'], counts2['l']],\n",
    "    [counts3['u'], counts3['u2m'], counts3['m'], counts3['m2l'], counts3['l']],\n",
    "    [counts4['u'], counts4['u2m'], counts4['m'], counts4['m2l'], counts4['l']],\n",
    "    [counts5['u'], counts5['u2m'], counts5['m'], counts5['m2l'], counts5['l']]], \n",
    "    index=[f'+$\\\\Delta$> {upper_HL}\\nn={HL_u.shape[0]}',f'+$\\\\Delta$$\\\\in$({middle_HL},{upper_HL}]\\n(n={HL_u2m.shape[0]})', f'$\\\\Delta$={middle_HL}\\n(n={HL_m.shape[0]})', f'-$\\\\Delta$$\\\\in$[{lower_HL},{middle_HL})\\n(n={HL_m2l.shape[0]})', f'-$\\\\Delta$< {lower_HL}\\nn={HL_l.shape[0]}'],\n",
    "    columns=[f'+$\\\\Delta$> {upper_PC}\\nn={PC_u.shape[0]}', f'+$\\\\Delta$$\\\\in$({middle_PC},{upper_PC}]\\nn={PC_u2m.shape[0]}', f'$\\\\Delta$={middle_PC}\\nn={PC_m.shape[0]}',f'-$\\\\Delta$$\\\\in$[{lower_PC},{middle_PC})\\nn={PC_m2l.shape[0]}',  f'-$\\\\Delta$< {lower_PC}\\nn={PC_l.shape[0]}'])\n",
    "    \n",
    "    # plot the matrix: \n",
    "    ax = axes[row, col]\n",
    "    sns.heatmap(matrix_df, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    \n",
    "    # plot the confusion matrix:\n",
    "    ax.set_title(f'Confusion matrix of the $Log_{2}$ fold $\\\\Delta$ in\\n protein counts and half life', fontsize=15, pad=15, )\n",
    "    ax.set_xlabel(f'$Log_{2}$ fold $\\\\Delta$ in Protein Counts')\n",
    "    ax.set_ylabel(f'$Log_{2}$ fold $\\\\Delta$ in Half Life')\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "fig, axes = plt.subplots(figsize=(30,12),  nrows=2, ncols=2, gridspec_kw={'height_ratios': [1, 1], 'width_ratios': [3, 1]})\n",
    "fig.tight_layout()\n",
    "\n",
    "# plot the plots \n",
    "make_subplot(0, 0, df, column0, 'half life', HL_upper, HL_middle, HL_lower, title0)\n",
    "make_subplot(1, 0, df, column1, 'average protein counts', PC_upper, PC_middle, PC_lower, title1)\n",
    "make_histogram(0, 1, df, column1, bins_histogram, upper_histogram, lower_histogram)\n",
    "make_matrix(1, 1, df, column0, column1, HL_upper, HL_middle, HL_lower, PC_upper, PC_middle, PC_lower)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth_bar_graph)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# MAKE THE VALIDATION MATRIX:\n",
    "column = 'HL_log2_fold_change'\n",
    "validaiton_column = 'Log10 Validation Data Average Monomer Counts'\n",
    "\n",
    "CLClim3NE1_HLs_Clim3_above_upper, CLClim3NE1_HLs_Clim3_upper_to_zero, CLClim3NE1_HLs_Clim3_middle, CLClim3NE1_HLs_Clim3_0_to_lower, CLClim3NE1_HLs_Clim3_lower, words_u, words_u2m, words_m, words_m2l, words_l = obtain_data(df, column, HL_upper, HL_middle, HL_lower)\n",
    "\n",
    "\n",
    "# make the validation plot:\n",
    "def make_counts_comparison_with_upper_HL_change_data(row, col, whole_df, interest_df):\n",
    "    # define the axes:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # plot all of the proteins \n",
    "    sns.scatterplot(data=whole_df, x=whole_df[CLNE_new_name], y=whole_df[CLClimNE_new_name], color='grey', size=0.1, alpha=0.1, ax=ax, )\n",
    "    \n",
    "    # plot the proteins of interest:\n",
    "    sns.scatterplot(data=interest_df, x=interest_df[CLNE_new_name], y=interest_df[CLClimNE_new_name], color='red', alpha=0.5, ax=ax, )\n",
    "    ax.plot([0, 6], [0, 6], color='black', linestyle='--', linewidth=.5, alpha=0.5)\n",
    "    \n",
    "    # plot the common name of the proteins of interest:\n",
    "    for i, name in enumerate(interest_df['common_name'].unique()):\n",
    "        # get the index of the protein:\n",
    "        index = interest_df[interest_df['common_name'] == name].index[0]\n",
    "        # get the x and y values:\n",
    "        x = interest_df[CLNE_new_name][index]\n",
    "        y = interest_df[CLClimNE_new_name][index]\n",
    "        # plot the common name:\n",
    "        ax.text(x, y, name, ha='center', va='bottom', fontsize=8, rotation=0, )\n",
    "    \n",
    "    # Plot specs:\n",
    "    ax.set_title(f'Comparison of the average protein counts between the 2025 model\\nand 2020 model with proteins having the highest log$_{{2}}$ fold $\\\\Delta$\\nin half life highlighted ({interest_df.shape[0]} of {whole_df.shape[0]} total)', fontsize=10, pad=15, )\n",
    "    ax.set_xlabel(f'log$_{{10}}$(average protein counts +1),\\n2020 model ({CLNE_sequence})', fontsize=8, color=\"black\", )\n",
    "    ax.set_ylabel(f'log$_{{10}}$(average protein counts +1),\\n2025 model ({current_sequence})', fontsize=8, color=\"black\", )\n",
    "    \n",
    "    # add a legend:\n",
    "    #legend_labels = [f'all proteins (n={whole_df.shape[0]})', f'proteins with the largest +$\\\\Delta$\\n in half life (n={interest_df.shape[0]})']\n",
    "    #handles, _ = ax.get_legend_handles_labels()\n",
    "    #ax.legend(handles=handles, labels=legend_labels, loc='upper left', fontsize=8, frameon=False, markerscale=2)\n",
    "    ax.legend()\n",
    "    ax.get_legend().set_visible(False)\n",
    " \n",
    "\n",
    "def make_counts_comparison_with_lower_HL_change_data(row, col, whole_df, interest_df):\n",
    "    # define the axes:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # plot all of the proteins \n",
    "    sns.scatterplot(data=whole_df, x=whole_df[CLNE_new_name], y=whole_df[CLClimNE_new_name], color='grey', size=.1, alpha=0.1, ax=ax)\n",
    "    \n",
    "    # plot the proteins of interest:\n",
    "    sns.scatterplot(data=interest_df, x=interest_df[CLNE_new_name], y=interest_df[CLClimNE_new_name], color='blue', alpha=0.5, ax=ax)\n",
    "    ax.plot([0, 6], [0, 6], color='black', linestyle='--', linewidth=.5, alpha=0.5)\n",
    "\n",
    "    \n",
    "    # plot the common name of the proteins of interest:\n",
    "    for i, name in enumerate(interest_df['common_name'].unique()):\n",
    "        # get the index of the protein:\n",
    "        index = interest_df[interest_df['common_name'] == name].index[0]\n",
    "        # get the x and y values:\n",
    "        x = interest_df[CLNE_new_name][index]\n",
    "        y = interest_df[CLClimNE_new_name][index]\n",
    "        # plot the common name:\n",
    "        ax.text(x, y, name, ha='center', va='bottom', fontsize=8, rotation=0, )\n",
    "    \n",
    "    # Plot specs:\n",
    "    ax.set_title(f'Comparison of the average protein counts between the 2025 model\\nand 2020 model with proteins having the smallest log$_{{2}}$ fold $\\\\Delta$\\nin half life highlighted ({interest_df.shape[0]} of {whole_df.shape[0]} total)', fontsize=10, pad=15, )\n",
    "    ax.set_xlabel(f'log$_{{10}}$(average protein counts +1),\\n2020 model ({CLNE_sequence})', fontsize=8, color=\"black\", )\n",
    "    ax.set_ylabel(f'log$_{{10}}$(average protein counts +1),\\n2025 model ({current_sequence})', fontsize=8, color=\"black\", )\n",
    "    ax.legend()\n",
    "    ax.get_legend().set_visible(False)\n",
    "    \n",
    "# now make a plot for the validation comparison: \n",
    "def make_counts_comparison_with_upper_HL_change_validation_data(row, col, whole_df, interest_df):\n",
    "    # define the axes:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # clean up the data: \n",
    "    x_col = 'Log10 Validation Data Average Monomer Counts'\n",
    "    y_col = CLClimNE_new_name\n",
    "    y_col2 = CLNE_new_name\n",
    "\n",
    "    # remove proteins that have \"None\" in their y_col: \n",
    "    whole_df_to_plot = whole_df[whole_df[x_col].notna()]\n",
    "    interest_df_to_plot = interest_df[interest_df[x_col].notna()]\n",
    "\n",
    "    \n",
    "    # plot all of the proteins \n",
    "    sns.scatterplot(data=whole_df_to_plot, x=whole_df_to_plot[x_col], y=whole_df_to_plot[y_col], color='grey', size=.1, alpha=0.1, ax=ax,)\n",
    "    \n",
    "    # plot the proteins of interest:\n",
    "    sns.scatterplot(data=interest_df_to_plot, x=interest_df_to_plot[x_col], y=interest_df_to_plot[y_col], color='red', alpha=0.9, ax=ax)\n",
    "    sns.scatterplot(data=interest_df_to_plot, x=interest_df_to_plot[x_col], y=interest_df_to_plot[y_col2], color='black', alpha=0.5, ax=ax)\n",
    "    \n",
    "    # add a y=x dotted line:\n",
    "    ax.plot([0, 6], [0, 6], color='black', linestyle='--', linewidth=.5, alpha=0.5)\n",
    "    \n",
    "    # calculate the coefficent of determination for all proteins (y_true, y_pred are inputs, where here, y_true is the x values (validation data) and y_pred is the model data):\n",
    "    r2_2025_all = r2_score_y_equals_x(whole_df_to_plot[x_col], whole_df_to_plot[y_col])\n",
    "    r2_2020_all = r2_score_y_equals_x(whole_df_to_plot[x_col], whole_df_to_plot[y_col2])\n",
    "    \n",
    "    # calculate the R2 for counts above 30:\n",
    "    filtered_df_2025 = whole_df_to_plot[(whole_df_to_plot[x_col] > np.log10(30+1)) & (whole_df_to_plot[y_col] > np.log10(30+1))]\n",
    "    filtered_df_2020 = whole_df_to_plot[(whole_df_to_plot[x_col] > np.log10(30+1)) & (whole_df_to_plot[y_col2] > np.log10(30+1))]\n",
    "    r2_2025_all_above_30 = r2_score_y_equals_x(filtered_df_2025[x_col], filtered_df_2025[y_col])\n",
    "    r2_2020_all_above_30 = r2_score_y_equals_x(filtered_df_2020[x_col], filtered_df_2020[y_col2])\n",
    "    \n",
    "    # calcuate the R^2 for the 2020 vs 2025 model \n",
    "    r2_2025 = r2_score_y_equals_x(interest_df_to_plot[x_col], interest_df_to_plot[y_col])\n",
    "    r2_2020 = r2_score_y_equals_x(interest_df_to_plot[x_col], interest_df_to_plot[y_col2])\n",
    "    \n",
    "    ax.text(0.98, 0.26, f\"all proteins (n={whole_df_to_plot.shape[0]}):\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.23, f\"$R^2$ 2020 model: {r2_2020_all:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "    ax.text(0.98, 0.20, f\"$R^2$ 2025 model: {r2_2025_all:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='red')\n",
    "    ax.text(0.98, 0.17, f\"$R^2$ for counts > 30:\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.14, f\"2020 (n={filtered_df_2020.shape[0]}): {r2_2020_all_above_30:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "    ax.text(0.98, 0.11, f\"2025 (n={filtered_df_2025.shape[0]}): {r2_2025_all_above_30:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='red')\n",
    "    ax.text(0.98, 0.08, f\"select proteins (n={len(interest_df_to_plot[x_col])}):\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.02, f\"$R^2$ 2025 model: {r2_2025:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='red')\n",
    "    ax.text(0.98, 0.05, f\"$R^2$ 2020 model: {r2_2020:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "\n",
    "    \n",
    "    # plot the common name of the proteins of interest:\n",
    "    for i, name in enumerate(interest_df_to_plot['common_name'].unique()):\n",
    "        # get the index of the protein:\n",
    "        index = interest_df_to_plot[interest_df_to_plot['common_name'] == name].index[0]\n",
    "        # get the x and y values:\n",
    "        x = interest_df_to_plot[x_col][index]\n",
    "        y = interest_df_to_plot[y_col][index]\n",
    "        # plot the common name:\n",
    "        ax.text(x+.2, y, name, ha='center', va='bottom', fontsize=8, rotation=0, )\n",
    "        \n",
    "        # also make a line between the two: \n",
    "        y2 = interest_df_to_plot[y_col2][index]\n",
    "        difference = y - y2\n",
    "        if abs(difference) > 0.2:\n",
    "            dx = x-x\n",
    "            dy = y - y2\n",
    "            #ax.arrow([x, x], [y, y2], color='red', linewidth=.5, alpha=0.5)\n",
    "            ax.arrow(x, y2, dx, dy, color='red', linewidth=.5, alpha=0.5, head_width=0.1, head_length=0.15, length_includes_head=True)\n",
    "    \n",
    "    # Plot specs:\n",
    "    ax.set_title(f'Comparison of the average protein counts between the 2025 model \\nand validation data with proteins having the highest\\nlog$_{{2}}$ fold $\\\\Delta$ in half life highlighted ({len(interest_df_to_plot[x_col])} of {whole_df_to_plot.shape[0]} total)', fontsize=10, pad=15, )\n",
    "    ax.set_xlabel(f'log$_{{10}}$(average protein counts +1),\\nValidation Data (Schmidt et al. 2016)', fontsize=8, color=\"black\", )\n",
    "    ax.set_ylabel(f'log$_{{10}}$(average protein counts +1),\\n2025 model ({current_sequence})', fontsize=8, color=\"black\", )\n",
    "    ax.legend()\n",
    "    ax.get_legend().set_visible(False)\n",
    "\n",
    "\n",
    "# now make a plot for the validation comparison: \n",
    "def make_counts_comparison_with_lower_HL_change_validation_data(row, col, whole_df, interest_df):\n",
    "    # define the axes:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # clean up the data: \n",
    "    x_col = 'Log10 Validation Data Average Monomer Counts'\n",
    "    y_col = CLClimNE_new_name\n",
    "    y_col2 = CLNE_new_name\n",
    "\n",
    "    # remove proteins that have \"None\" in their y_col: \n",
    "    whole_df_to_plot = whole_df[whole_df[x_col].notna()]\n",
    "    interest_df_to_plot = interest_df[interest_df[x_col].notna()]\n",
    "\n",
    "    \n",
    "    # plot all of the proteins \n",
    "    sns.scatterplot(data=whole_df_to_plot, x=whole_df_to_plot[x_col], y=whole_df_to_plot[y_col], color='grey', size=.1, alpha=0.1, ax=ax,)\n",
    "    \n",
    "    # plot the proteins of interest:\n",
    "    sns.scatterplot(data=interest_df_to_plot, x=interest_df_to_plot[x_col], y=interest_df_to_plot[y_col], color='blue', alpha=0.9, ax=ax, )\n",
    "    sns.scatterplot(data=interest_df_to_plot, x=interest_df_to_plot[x_col], y=interest_df_to_plot[y_col2], color='black', alpha=0.5, ax=ax, \n",
    "                   )\n",
    "    \n",
    "    # add a y=x dotted line:\n",
    "    ax.plot([0, 6], [0, 6], color='black', linestyle='--', linewidth=.5, alpha=0.5)\n",
    "    \n",
    "    # plot the common name of the proteins of interest:\n",
    "    for i, name in enumerate(interest_df_to_plot['common_name'].unique()):\n",
    "        # get the index of the protein:\n",
    "        index = interest_df_to_plot[interest_df_to_plot['common_name'] == name].index[0]\n",
    "        # get the x and y values:\n",
    "        x = interest_df_to_plot[x_col][index]\n",
    "        y = interest_df_to_plot[y_col][index]\n",
    "        # plot the common name:\n",
    "        ax.text(x+.2, y, name, ha='center', va='bottom', fontsize=8, rotation=0, )\n",
    "        \n",
    "        # also make a line between the two: \n",
    "        y2 = interest_df_to_plot[y_col2][index]\n",
    "        difference = y - y2\n",
    "        if abs(difference) > 0.2:\n",
    "            dx = x-x\n",
    "            dy = y - y2\n",
    "            #ax.arrow([x, x], [y, y2], color='red', linewidth=.5, alpha=0.5)\n",
    "            ax.arrow(x, y2, dx, dy, color='blue', linewidth=.5, alpha=0.5, head_width=0.1, head_length=0.15, length_includes_head=True)\n",
    "    \n",
    "    # calculate the coefficent of determination for all proteins:\n",
    "    r2_2025_all = r2_score_y_equals_x(whole_df_to_plot[x_col], whole_df_to_plot[y_col])\n",
    "    r2_2020_all = r2_score_y_equals_x(whole_df_to_plot[x_col], whole_df_to_plot[y_col2])\n",
    "    \n",
    "    # calculate the R2 for counts above 30:\n",
    "    filtered_df_2025 = whole_df_to_plot[(whole_df_to_plot[x_col] > np.log10(30+1)) & (whole_df_to_plot[y_col] > np.log10(30+1))]\n",
    "    filtered_df_2020 = whole_df_to_plot[(whole_df_to_plot[x_col] > np.log10(30+1)) & (whole_df_to_plot[y_col2] > np.log10(30+1))]\n",
    "    r2_2025_all_above_30 = r2_score_y_equals_x(filtered_df_2025[x_col], filtered_df_2025[y_col])\n",
    "    r2_2020_all_above_30 = r2_score_y_equals_x(filtered_df_2020[x_col], filtered_df_2020[y_col2])\n",
    "    \n",
    "    # calcuate the R^2 for the 2020 vs 2025 model \n",
    "    r2_2025 = r2_score_y_equals_x(interest_df_to_plot[x_col], interest_df_to_plot[y_col])\n",
    "    r2_2020 = r2_score_y_equals_x(interest_df_to_plot[x_col], interest_df_to_plot[y_col2])\n",
    "    \n",
    "    ax.text(0.98, 0.26, f\"all proteins (n={whole_df_to_plot.shape[0]}):\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.23, f\"$R^2$ 2020 model: {r2_2020_all:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "    ax.text(0.98, 0.20, f\"$R^2$ 2025 model: {r2_2025_all:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='blue')\n",
    "    ax.text(0.98, 0.17, f\"$R^2$ for counts > 30:\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.14, f\"2020 (n={filtered_df_2020.shape[0]}): {r2_2020_all_above_30:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "    ax.text(0.98, 0.11, f\"2025 (n={filtered_df_2025.shape[0]}): {r2_2025_all_above_30:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='blue')\n",
    "    ax.text(0.98, 0.08, f\"select proteins (n={len(interest_df_to_plot[x_col])}):\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='black')\n",
    "    ax.text(0.98, 0.02, f\"$R^2$ 2025 model: {r2_2025:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='blue')\n",
    "    ax.text(0.98, 0.05, f\"$R^2$ 2020 model: {r2_2020:.2f}\", transform=ax.transAxes, ha='right', va='bottom',  fontsize=8, color='grey')\n",
    "    \n",
    "    # Plot specs:\n",
    "    ax.set_title(f'Comparison of the average protein counts between the 2025 model \\nand validation data with proteins having the smallest\\nlog$_{{2}}$ fold $\\\\Delta$ in half life highlighted ({len(interest_df_to_plot[x_col])} of {whole_df_to_plot.shape[0]} total)', fontsize=10, pad=15, )\n",
    "    ax.set_xlabel(f'log$_{{10}}$(average protein counts +1),\\nValidation Data (Schmidt et al. 2016)', fontsize=8, color=\"black\", )\n",
    "    ax.set_ylabel(f'log$_{{10}}$(average protein counts +1),\\n2025 model ({current_sequence})', fontsize=8, color=\"black\", )\n",
    "    legend_labels = [f\"proteins with the largest -$\\\\Delta$\\nin half life in the 2025 model (n={interest_df_to_plot.shape[0]})\",  f\"2020 model value\"]\n",
    "    ax.legend()\n",
    "    ax.get_legend().set_visible(False)\n",
    "\n",
    "\n",
    "# MAKE THE PLOT\n",
    "# using this: https://sharkcoder.com/data-visualization/mpl-bidirectional\n",
    "fig, axes = plt.subplots(figsize=(10,10),  nrows=2, ncols=2, gridspec_kw={'height_ratios': [1, 1], 'width_ratios': [1, 1]})\n",
    "fig.tight_layout()\n",
    "\n",
    "# plot the plots \n",
    "make_counts_comparison_with_upper_HL_change_data(0, 0, combined_df, CLClim3NE1_HLs_Clim3_above_upper)\n",
    "make_counts_comparison_with_lower_HL_change_data(0, 1, combined_df, CLClim3NE1_HLs_Clim3_lower)\n",
    "make_counts_comparison_with_upper_HL_change_validation_data(1, 0, combined_df, CLClim3NE1_HLs_Clim3_above_upper)\n",
    "make_counts_comparison_with_lower_HL_change_validation_data(1, 1, combined_df, CLClim3NE1_HLs_Clim3_lower)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "# save the figure:\n",
    "out_pth = os.path.expanduser(out_pth_validation_matrix)\n",
    "output_dir = os.path.dirname(out_pth)\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "plt.savefig(out_pth, dpi=300, bbox_inches='tight')\n"
   ],
   "id": "f2657d709a4a48c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot all 8 graphs in one figure",
   "id": "40c7233b2d94e986"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Open the two images\n",
    "image1 = Image.open(out_pth_bar_graph)\n",
    "image2 = Image.open(out_pth_validation_matrix)\n",
    "\n",
    "# Resize the second image to match the width of the first image\n",
    "image2_resized = image2.resize((image1.width, int(image2.height * (image1.width / image2.width))), Image.LANCZOS)\n",
    "\n",
    "# Assuming you want to stack them vertically\n",
    "total_height = image1.height + image2_resized.height\n",
    "max_width = max(image1.width, image2_resized.width)\n",
    "\n",
    "# Create a new blank image with the total height and max width\n",
    "combined_image = Image.new(\"RGB\", (max_width, total_height))\n",
    "\n",
    "# Paste the first image\n",
    "combined_image.paste(image1, (0, 0))\n",
    "\n",
    "# Paste the resized second image\n",
    "combined_image.paste(image2_resized, (0, image1.height))\n",
    "\n",
    "# Save the combined image with specific DPI\n",
    "out_pth_all_graphs = os.path.join(out_pth_root, \"all_graphs.png\")\n",
    "output_dir_all_graphs = os.path.dirname(out_pth_all_graphs)\n",
    "os.makedirs(output_dir_all_graphs, exist_ok=True)  # Create the directory if it does not exist\n",
    "\n",
    "# Save the image and specify DPI using the save method's `dpi` parameter\n",
    "combined_image.save(out_pth_all_graphs, dpi=(300, 300))  # Save the combined image with 300 DPI\n",
    "\n",
    "plt.close(fig)"
   ],
   "id": "378fd316702b8999",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3690db4317609543",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
