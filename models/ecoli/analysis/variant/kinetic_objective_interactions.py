"""
Analysis of fluxes for the factorial design experiments generated by the
variant metabolism_kinetic_objective_interactions.

@organization: Covert Lab, Department of Bioengineering, Stanford University
"""

from __future__ import absolute_import, division, print_function

import cPickle
import csv
import os

import numpy as np
from scipy.stats import pearsonr

from models.ecoli.analysis import variantAnalysisPlot
from models.ecoli.analysis.AnalysisPaths import AnalysisPaths
from models.ecoli.processes.metabolism import COUNTS_UNITS, VOLUME_UNITS, TIME_UNITS, MASS_UNITS
from models.ecoli.sim.variants.metabolism_kinetic_objective_interactions import get_disabled_constraints
from wholecell.io.tablereader import TableReader
from wholecell.utils import constants, filepath, units


# IDs of interest
SUCC_ID = 'SUCCINATE-DEHYDROGENASE-UBIQUINONE-RXN-SUC/UBIQUINONE-8//FUM/CPD-9956.31.'
NADH_ID = 'NADH-DEHYDROG-A-RXN-NADH/UBIQUINONE-8/PROTON//NAD/CPD-9956/PROTON.46. (reverse)'
GLC_ID = 'GLC[p]'
REACTIONS = [SUCC_ID, NADH_ID]
EXCHANGES = [GLC_ID]

# Flux units
MODEL_FLUX_UNITS = COUNTS_UNITS / MASS_UNITS / TIME_UNITS
OUTPUT_FLUX_UNITS = units.mmol / units.g / units.h
FLUX_CONVERSION = MODEL_FLUX_UNITS.asNumber(OUTPUT_FLUX_UNITS)


class Plot(variantAnalysisPlot.VariantAnalysisPlot):
	def do_plot(self, inputDir, plotOutDir, plotOutFileName, simDataFile, validationDataFile, metadata):
		if not os.path.isdir(inputDir):
			raise Exception, 'inputDir does not currently exist as a directory'

		filepath.makedirs(plotOutDir)

		ap = AnalysisPaths(inputDir, variant_plot=True)
		variants = ap.get_variants()

		# Load sim_data
		with open(os.path.join(inputDir, 'kb', constants.SERIALIZED_FIT1_FILENAME), 'rb') as f:
			sim_data = cPickle.load(f)
		cell_density = sim_data.constants.cellDensity.asNumber(MASS_UNITS / VOLUME_UNITS)

		# Load validation_data
		with open(validationDataFile, "rb") as f:
			validation_data = cPickle.load(f)
		toyaReactions = validation_data.reactionFlux.toya2010fluxes["reactionID"]
		toyaFluxes = validation_data.reactionFlux.toya2010fluxes["reactionFlux"]
		toyaStdev = validation_data.reactionFlux.toya2010fluxes["reactionFluxStdev"]
		toyaFluxesDict = dict(zip(toyaReactions, toyaFluxes))
		toyaStdevDict = dict(zip(toyaReactions, toyaStdev))

		save_output_file = os.path.join(plotOutDir, plotOutFileName + '.tsv')
		with open(save_output_file, 'w') as f:
			fieldnames = [
				'variant',
				'disabled reactions',
				'succ avg sim flux (mmol/gDCW/h)',
				'succ target avg (mmol/gDCW/h)',
				'succ distance from toya (mmol/gDCW/h)',
				'nadh avg sim flux (mmol/gDCW/h)',
				'nadh target avg (mmol/gDCW/h)',
				'glc avg sim flux (mmol/gDCW/h)',
				'Pearson R Toya',
				]
			writer = csv.DictWriter(f, delimiter='\t', fieldnames=fieldnames)
			writer.writeheader()

		for variant in variants:
			# initialize kinetic flux comparison
			target_fluxes = {entry: [] for entry in REACTIONS}
			exchange_fluxes = {entry: [] for entry in EXCHANGES}
			reaction_fluxes = {entry: [] for entry in REACTIONS}

			modelFluxes = {}
			toyaOrder = []
			for rxn in toyaReactions:
				modelFluxes[rxn] = []
				toyaOrder.append(rxn)

			for sim_dir in ap.get_cells(variant=[variant]):
				simOutDir = os.path.join(sim_dir, "simOut")

				try:
					# Listeners used
					massListener = TableReader(os.path.join(simOutDir, "Mass"))
					fbaResults = TableReader(os.path.join(simOutDir, "FBAResults"))
					enzymeKineticsReader = TableReader(os.path.join(simOutDir, "EnzymeKinetics"))

					## Read from mass listener
					cellMass = massListener.readColumn("cellMass")
					# skip if no data
					if cellMass.shape is ():
						continue
					dryMass = massListener.readColumn("dryMass")
				except Exception as e:
					print(e)
					continue

				coefficient = (dryMass / cellMass * cell_density).reshape(-1, 1)

				## Read from FBA listener
				reactionIDs = {r: i for i, r in enumerate(fbaResults.readAttribute("reactionIDs"))}
				exMolec = {m: i for i, m in enumerate(fbaResults.readAttribute("externalMoleculeIDs"))}
				reactionFluxes = FLUX_CONVERSION * (fbaResults.readColumn("reactionFluxes") / coefficient)[1:, :]
				exFlux = fbaResults.readColumn("externalExchangeFluxes")[1:, :]

				## Read from EnzymeKinetics listener
				constrainedReactions = {r: i for i, r in enumerate(enzymeKineticsReader.readAttribute("constrainedReactions"))}
				targetFluxes = FLUX_CONVERSION * (enzymeKineticsReader.readColumn("targetFluxes") / coefficient)[1:, :]

				## Append values for relevant reactions.
				# append to exchanges
				for entry in EXCHANGES:
					exchange_fluxes[entry].extend(list(exFlux[:, exMolec[entry]]))
				# append to reaction fluxes
				for entry in REACTIONS:
					reaction_fluxes[entry].extend(list(reactionFluxes[:, reactionIDs[entry]]))
					if entry in constrainedReactions:
						target_fluxes[entry].extend(list(targetFluxes[:, constrainedReactions[entry]]))
					else:
						target_fluxes[entry].extend([0])

				## get all Toya reactions, and corresponding simulated fluxes.
				toya_idx = {r: [] for r in toyaReactions}
				for rxn, i in reactionIDs.items():
					rxn = rxn.split(' (reverse)')
					if len(rxn) > 1:
						i = -i
					rxn = rxn[0].split('__')[0]
					if rxn in toya_idx:
						toya_idx[rxn] += [i]
				for toyaReaction, reaction_idx in toya_idx.items():
					flux_time_course = np.sum([np.sign(i) * reactionFluxes[:, np.abs(i)] for i in reaction_idx], axis=0)
					modelFluxes[toyaReaction].append(flux_time_course.mean())

			## Flux comparison with Toya
			toyaVsReactionAve = []
			rxn_order = []
			for rxn, toyaFlux in toyaFluxesDict.iteritems():
				rxn_order.append(rxn)
				if rxn in modelFluxes:
					toyaVsReactionAve.append((np.mean(modelFluxes[rxn]), toyaFlux.asNumber(OUTPUT_FLUX_UNITS), np.std(modelFluxes[rxn]), toyaStdevDict[rxn].asNumber(OUTPUT_FLUX_UNITS)))

			toyaVsReactionAve = np.array(toyaVsReactionAve)
			rWithAll = pearsonr(toyaVsReactionAve[:,0], toyaVsReactionAve[:,1])

			succ_avg_sim_flux = toyaVsReactionAve[rxn_order.index(SUCC_ID), 0]
			succ_toya_flux = toyaVsReactionAve[rxn_order.index(SUCC_ID), 1]
			succ_difference = succ_avg_sim_flux - succ_toya_flux

			# SUCC
			succ_avg_sim_flux = np.mean(reaction_fluxes[SUCC_ID])
			succ_target_avg = np.mean(target_fluxes[SUCC_ID])

			# NADH
			nadh_avg_sim_flux = np.mean(reaction_fluxes[NADH_ID])
			nadh_target_avg = np.mean(target_fluxes[NADH_ID])

			glc_avg_sim_flux = np.mean(exchange_fluxes[GLC_ID])

			# list of 4-character strings, for each disabled reaction
			additional_disabled_reduced = [c[:4] for c in get_disabled_constraints(variant)[1]]
			with open(save_output_file, 'a') as f:
				append_line = [
					variant,
					str(additional_disabled_reduced),
					succ_avg_sim_flux,
					succ_target_avg,
					succ_difference,
					nadh_avg_sim_flux,
					nadh_target_avg,
					glc_avg_sim_flux,
					rWithAll,
					]

				writer = csv.writer(f, delimiter='\t')
				writer.writerow(append_line)


if __name__ == "__main__":
	Plot().cli()