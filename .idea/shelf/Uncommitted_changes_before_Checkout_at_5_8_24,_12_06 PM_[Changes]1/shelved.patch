Index: models/ecoli/analysis/parca/template.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\nTemplate for parca analysis plots\n\"\"\"\n\nimport pickle\nimport os\n\nfrom matplotlib import pyplot as plt\n# noinspection PyUnresolvedReferences\nimport numpy as np\n\nfrom models.ecoli.analysis import parcaAnalysisPlot\nfrom wholecell.analysis.analysis_tools import exportFigure\nfrom wholecell.utils import constants\n\n\nclass Plot(parcaAnalysisPlot.ParcaAnalysisPlot):\n\tdef do_plot(self, input_dir, plot_out_dir, plot_out_filename, sim_data_file, validation_data_file, metadata):\n\t\twith open(os.path.join(input_dir, constants.SERIALIZED_RAW_DATA), 'rb') as f:\n\t\t\traw_data = pickle.load(f)\n\t\twith open(sim_data_file, 'rb') as f:\n\t\t\tsim_data = pickle.load(f)\n\t\twith open(validation_data_file, 'rb') as f:\n\t\t\tvalidation_data = pickle.load(f)\n\n\t\tplt.figure()\n\n\t\t### Create Plot ###\n\n\t\tplt.tight_layout()\n\t\texportFigure(plt, plot_out_dir, plot_out_filename, metadata)\n\t\tplt.close('all')\n\n\nif __name__ == \"__main__\":\n\tPlot().cli()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/models/ecoli/analysis/parca/template.py b/models/ecoli/analysis/parca/template.py
--- a/models/ecoli/analysis/parca/template.py	
+++ b/models/ecoli/analysis/parca/template.py	
@@ -22,7 +22,8 @@
 			sim_data = pickle.load(f)
 		with open(validation_data_file, 'rb') as f:
 			validation_data = pickle.load(f)
-
+		import ipdb
+		ipdb.set_trace()
 		plt.figure()
 
 		### Create Plot ###
Index: reconstruction/ecoli/knowledge_base_raw.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\nKnowledgeBase for Ecoli\nWhole-cell knowledge base for Ecoli. Contains all raw, un-fit data processed\ndirectly from CSV flat files.\n\n\"\"\"\nimport io\nimport os\nimport json\nfrom typing import List, Dict\nimport warnings\n\nfrom reconstruction.spreadsheets import read_tsv\nfrom wholecell.io import tsv\nfrom wholecell.utils import units  # used by eval()\n\nFLAT_DIR = os.path.join(os.path.dirname(__file__), \"flat\")\nLIST_OF_DICT_FILENAMES = [\n\t\"amino_acid_export_kms.tsv\",\n\t\"amino_acid_export_kms_removed.tsv\",\n\t\"amino_acid_pathways.tsv\",\n\t\"amino_acid_uptake_rates.tsv\",\n\t\"amino_acid_uptake_rates_removed.tsv\",\n\t\"biomass.tsv\",\n\t\"compartments.tsv\",\n\t\"complexation_reactions.tsv\",\n\t\"complexation_reactions_added.tsv\",\n\t\"complexation_reactions_modified.tsv\",\n\t\"complexation_reactions_removed.tsv\",\n\t\"disabled_kinetic_reactions.tsv\",\n\t\"dna_sites.tsv\",\n\t\"dry_mass_composition.tsv\",\n\t\"endoRNases.tsv\",\n\t\"equilibrium_reaction_rates.tsv\",\n\t\"equilibrium_reactions.tsv\",\n\t\"equilibrium_reactions_added.tsv\",\n\t\"equilibrium_reactions_removed.tsv\",\n\t\"fold_changes.tsv\",\n\t\"fold_changes_nca.tsv\",\n\t\"fold_changes_removed.tsv\",\n\t\"footprint_sizes.tsv\",\n\t\"genes.tsv\",\n\t\"growth_rate_dependent_parameters.tsv\",\n\t\"linked_metabolites.tsv\",\n\t\"metabolic_reactions.tsv\",\n\t\"metabolic_reactions_added.tsv\",\n\t\"metabolic_reactions_modified.tsv\",\n\t\"metabolic_reactions_removed.tsv\",\n\t\"metabolism_kinetics.tsv\",\n\t\"metabolite_concentrations.tsv\",\n\t\"metabolite_concentrations_removed.tsv\",\n\t\"metabolites.tsv\",\n\t\"metabolites_added.tsv\",\n\t\"modified_proteins.tsv\",\n\t\"molecular_weight_keys.tsv\",\n\t\"ppgpp_fc.tsv\",\n\t\"ppgpp_regulation.tsv\",\n\t\"ppgpp_regulation_added.tsv\",\n\t\"ppgpp_regulation_removed.tsv\",\n\t\"protein_half_lives_measured.tsv\",\n\t\"protein_half_lives_n_end_rule.tsv\",\n\t\"protein_half_lives_pulsed_silac.tsv\",\n\t\"proteins.tsv\",\n\t\"relative_metabolite_concentrations.tsv\",\n\t\"rna_half_lives.tsv\",\n\t\"rna_maturation_enzymes.tsv\",\n\t\"rnas.tsv\",\n\t\"secretions.tsv\",\n\t\"sequence_motifs.tsv\",\n\t\"transcription_factors.tsv\",\n\t# \"transcription_units.tsv\",  # special cased in the constructor\n\t\"transcription_units_added.tsv\",\n\t\"transcription_units_removed.tsv\",\n\t\"transcriptional_attenuation.tsv\",\n\t\"transcriptional_attenuation_removed.tsv\",\n\t\"tf_one_component_bound.tsv\",\n\t\"translation_efficiency.tsv\",\n\t\"trna_charging_reactions.tsv\",\n\t\"trna_charging_reactions_added.tsv\",\n\t\"trna_charging_reactions_removed.tsv\",\n\t\"two_component_systems.tsv\",\n\t\"two_component_system_templates.tsv\",\n\tos.path.join(\"mass_fractions\", \"glycogen_fractions.tsv\"),\n\tos.path.join(\"mass_fractions\", \"ion_fractions.tsv\"),\n\tos.path.join(\"mass_fractions\", \"LPS_fractions.tsv\"),\n\tos.path.join(\"mass_fractions\", \"lipid_fractions.tsv\"),\n\tos.path.join(\"mass_fractions\", \"murein_fractions.tsv\"),\n\tos.path.join(\"mass_fractions\", \"soluble_fractions.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_ratio_to_16SrRNA_0p4.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_ratio_to_16SrRNA_0p7.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_ratio_to_16SrRNA_1p6.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_ratio_to_16SrRNA_1p07.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_ratio_to_16SrRNA_2p5.tsv\"),\n\tos.path.join(\"trna_data\", \"trna_growth_rates.tsv\"),\n\tos.path.join(\"rna_seq_data\", \"rnaseq_rsem_tpm_mean.tsv\"),\n\tos.path.join(\"rna_seq_data\", \"rnaseq_rsem_tpm_std.tsv\"),\n\tos.path.join(\"rna_seq_data\", \"rnaseq_seal_rpkm_mean.tsv\"),\n\tos.path.join(\"rna_seq_data\", \"rnaseq_seal_rpkm_std.tsv\"),\n\tos.path.join(\"rrna_options\", \"remove_rrff\", \"genes_removed.tsv\"),\n\tos.path.join(\"rrna_options\", \"remove_rrff\", \"rnas_removed.tsv\"),\n\tos.path.join(\"rrna_options\", \"remove_rrff\", \"transcription_units_modified.tsv\"),\n\tos.path.join(\"rrna_options\", \"remove_rrna_operons\", \"transcription_units_added.tsv\"),\n\tos.path.join(\"rrna_options\", \"remove_rrna_operons\", \"transcription_units_removed.tsv\"),\n\tos.path.join(\"condition\", \"tf_condition.tsv\"),\n\tos.path.join(\"condition\", \"condition_defs.tsv\"),\n\tos.path.join(\"condition\", \"environment_molecules.tsv\"),\n\tos.path.join(\"condition\", \"timelines_def.tsv\"),\n\tos.path.join(\"condition\", \"media_recipes.tsv\"),\n\tos.path.join(\"condition\", \"media\", \"5X_supplement_EZ.tsv\"),\n\tos.path.join(\"condition\", \"media\", \"MIX0-55.tsv\"),\n\tos.path.join(\"condition\", \"media\", \"MIX0-57.tsv\"),\n\tos.path.join(\"condition\", \"media\", \"MIX0-58.tsv\"),\n\tos.path.join(\"condition\", \"media\", \"MIX0-844.tsv\"),\n\tos.path.join(\"base_codes\", \"amino_acids.tsv\"),\n\tos.path.join(\"base_codes\", \"dntp.tsv\"),\n\tos.path.join(\"base_codes\", \"nmp.tsv\"),\n\tos.path.join(\"base_codes\", \"ntp.tsv\"),\n\tos.path.join(\"adjustments\", \"amino_acid_pathways.tsv\"),\n\tos.path.join(\"adjustments\", \"balanced_translation_efficiencies.tsv\"),\n\tos.path.join(\"adjustments\", \"translation_efficiencies_adjustments.tsv\"),\n\tos.path.join(\"adjustments\", \"rna_expression_adjustments.tsv\"),\n\tos.path.join(\"adjustments\", \"rna_deg_rates_adjustments.tsv\"),\n\tos.path.join(\"adjustments\", \"protein_deg_rates_adjustments.tsv\"),\n\tos.path.join(\"adjustments\", \"relative_metabolite_concentrations_changes.tsv\"),\n\t]\nSEQUENCE_FILE = 'sequence.fasta'\nLIST_OF_PARAMETER_FILENAMES = [\n\t\"dna_supercoiling.tsv\",\n\t\"parameters.tsv\",\n\t\"mass_parameters.tsv\",\n\tos.path.join(\"new_gene_data\", \"new_gene_baseline_expression_parameters.tsv\"),\n\t]\n\nREMOVED_DATA = {\n\t'amino_acid_export_kms': 'amino_acid_export_kms_removed',\n\t'amino_acid_uptake_rates': 'amino_acid_uptake_rates_removed',\n\t'complexation_reactions': 'complexation_reactions_removed',\n\t'equilibrium_reactions': 'equilibrium_reactions_removed',\n\t'fold_changes': 'fold_changes_removed',\n\t'fold_changes_nca': 'fold_changes_removed',\n\t'metabolic_reactions': 'metabolic_reactions_removed',\n\t'metabolite_concentrations': 'metabolite_concentrations_removed',\n\t'ppgpp_regulation': 'ppgpp_regulation_removed',\n\t'transcriptional_attenuation': 'transcriptional_attenuation_removed',\n\t'trna_charging_reactions': 'trna_charging_reactions_removed',\n\t}\nMODIFIED_DATA = {\n\t'complexation_reactions': 'complexation_reactions_modified',\n\t'metabolic_reactions': 'metabolic_reactions_modified',\n\t}\n\nADDED_DATA = {\n\t'complexation_reactions': 'complexation_reactions_added',\n\t'equilibrium_reactions': 'equilibrium_reactions_added',\n\t'metabolic_reactions': 'metabolic_reactions_added',\n\t'metabolites': 'metabolites_added',\n\t'ppgpp_regulation': 'ppgpp_regulation_added',\n\t'trna_charging_reactions': 'trna_charging_reactions_added',\n\t}\n\n\nclass DataStore(object):\n\tdef __init__(self):\n\t\tpass\n\nclass KnowledgeBaseEcoli(object):\n\t\"\"\" KnowledgeBaseEcoli \"\"\"\n\n\tdef __init__(self, operons_on: bool, remove_rrna_operons: bool, remove_rrff: bool, stable_rrna: bool, new_genes_option: str=\"off\"):\n\t\tself.operons_on = operons_on\n\t\tself.stable_rrna = stable_rrna\n\t\tself.new_genes_option = new_genes_option\n\n\t\tif not operons_on and remove_rrna_operons:\n\t\t\twarnings.warn(\"Setting the 'remove_rrna_operons' option to 'True'\"\n\t\t\t              \" has no effect on the simulations when the 'operon'\"\n\t\t\t              \" option is set to 'off'.\")\n\n\t\tself.compartments: List[dict] = []  # mypy can't track setattr(self, attr_name, rows)\n\t\tself.transcription_units: List[dict] = []\n\n\t\t# Make copies to prevent issues with sticky global variables when\n\t\t# running multiple operon workflows through Fireworks\n\t\tself.list_of_dict_filenames: List[str] = LIST_OF_DICT_FILENAMES.copy()\n\t\tself.list_of_parameter_filenames: List[str] = LIST_OF_PARAMETER_FILENAMES.copy()\n\t\tself.removed_data: Dict[str, str] = REMOVED_DATA.copy()\n\t\tself.modified_data: Dict[str, str] = MODIFIED_DATA.copy()\n\t\tself.added_data: Dict[str, str] = ADDED_DATA.copy()\n\t\tself.new_gene_added_data: Dict[str,str] = {}\n\t\tself.parameter_file_attribute_names: List[str] = [\n\t\t\tos.path.splitext(os.path.basename(filename))[0]\n\t\t\tfor filename in self.list_of_parameter_filenames\n\t\t\t]\n\n\t\tif self.operons_on:\n\t\t\tself.list_of_dict_filenames.append('transcription_units.tsv')\n\t\t\tif remove_rrna_operons:\n\t\t\t\t# Use alternative file with all rRNA transcription units if\n\t\t\t\t# remove_rrna_operons option was used\n\t\t\t\tself.removed_data.update({\n\t\t\t\t\t'transcription_units': 'rrna_options.remove_rrna_operons.transcription_units_removed',\n\t\t\t\t\t})\n\t\t\t\tself.added_data.update({\n\t\t\t\t\t'transcription_units': 'rrna_options.remove_rrna_operons.transcription_units_added',\n\t\t\t\t\t})\n\t\t\telse:\n\t\t\t\tself.removed_data.update({\n\t\t\t\t\t'transcription_units': 'transcription_units_removed',\n\t\t\t\t})\n\t\t\t\tself.added_data.update({\n\t\t\t\t\t'transcription_units': 'transcription_units_added',\n\t\t\t\t\t})\n\n\t\tif remove_rrff:\n\t\t\tself.list_of_parameter_filenames.append(\n\t\t\t\tos.path.join(\"rrna_options\", \"remove_rrff\", \"mass_parameters_modified.tsv\"))\n\t\t\tself.removed_data.update({\n\t\t\t\t'genes': 'rrna_options.remove_rrff.genes_removed',\n\t\t\t\t'rnas': 'rrna_options.remove_rrff.rnas_removed',\n\t\t\t\t})\n\t\t\tself.modified_data.update({\n\t\t\t\t'mass_parameters': 'rrna_options.remove_rrff.mass_parameters_modified',\n\t\t\t\t})\n\t\t\tif self.operons_on:\n\t\t\t\tself.modified_data.update({\n\t\t\t\t\t'transcription_units': 'rrna_options.remove_rrff.transcription_units_modified',\n\t\t\t\t\t})\n\n\t\tif self.new_genes_option != 'off':\n\t\t\tnew_gene_subdir = new_genes_option\n\t\t\tnew_gene_path = os.path.join('new_gene_data', new_gene_subdir)\n\t\t\tassert os.path.isdir(os.path.join(FLAT_DIR, new_gene_path)), (\n\t\t\t\t\"This new_genes_data subdirectory is invalid.\")\n\t\t\tnested_attr = 'new_gene_data.' + new_gene_subdir + \".\"\n\n\t\t\t# These files do not need to be joined to existing files\n\t\t\tself.list_of_dict_filenames.append(\n\t\t\t\tos.path.join(new_gene_path, 'insertion_location.tsv'))\n\t\t\tself.list_of_dict_filenames.append(\n\t\t\t\tos.path.join(new_gene_path, 'gene_sequences.tsv'))\n\n\t\t\t# These files need to be joined to existing files\n\t\t\tnew_gene_shared_files = [\n\t\t\t\t'genes',\n\t\t\t\t'rnas',\n\t\t\t\t'proteins',\n\t\t\t\t'rna_half_lives',\n\t\t\t\t'protein_half_lives_measured',\n\t\t\t\t]\n\t\t\tfor f in new_gene_shared_files:\n\t\t\t\tfile_path = os.path.join(new_gene_path, f + '.tsv')\n\t\t\t\t# If these files are empty, fill in with default values at a\n\t\t\t\t# later point\n\t\t\t\tassert os.path.isfile(os.path.join(FLAT_DIR, file_path)), (\n\t\t\t\t\tf\"File {f}.tsv must be present in the new_genes_data\"\n\t\t\t\t\tf\" subdirectory {new_gene_subdir}.\")\n\t\t\t\tself.list_of_dict_filenames.append(file_path)\n\t\t\t\tself.new_gene_added_data.update({f: nested_attr + f})\n\n\t\t# Load raw data from TSV files\n\t\tfor filename in self.list_of_dict_filenames:\n\t\t\tself._load_tsv(FLAT_DIR, os.path.join(FLAT_DIR, filename))\n\n\t\tfor filename in self.list_of_parameter_filenames:\n\t\t\tself._load_parameters(FLAT_DIR, os.path.join(FLAT_DIR, filename))\n\n\t\tself.genome_sequence = self._load_sequence(\n\t\t\tos.path.join(FLAT_DIR, SEQUENCE_FILE))\n\n\t\tself._prune_data()\n\n\t\tself._join_data()\n\t\tself._modify_data()\n\n\t\tif self.new_genes_option != 'off':\n\t\t\tself._check_new_gene_ids(nested_attr)\n\n\t\t\tinsert_pos = self._update_gene_insertion_location(nested_attr)\n\n\t\t\tinsertion_sequence = self._get_new_gene_sequence(nested_attr)\n\n\t\t\tinsert_end = self._update_gene_locations(nested_attr, insert_pos)\n\t\t\tself.new_gene_added_data.update({'genes': nested_attr+'genes'})\n\n\t\t\tself.genome_sequence = (self.genome_sequence[:insert_pos]\n\t\t\t\t+ insertion_sequence + self.genome_sequence[insert_pos:])\n\t\t\tassert self.genome_sequence[insert_pos:(insert_end + 1)] == insertion_sequence\n\n\t\t\tself.added_data = self.new_gene_added_data\n\t\t\tself._join_data()\n\n\tdef _load_tsv(self, dir_name, file_name):\n\t\tpath = self\n\t\tfor sub_path in file_name[len(dir_name) + 1 : ].split(os.path.sep)[:-1]:\n\t\t\tif not hasattr(path, sub_path):\n\t\t\t\tsetattr(path, sub_path, DataStore())\n\t\t\tpath = getattr(path, sub_path)\n\t\tattr_name = file_name.split(os.path.sep)[-1].split(\".\")[0]\n\t\tsetattr(path, attr_name, [])\n\n\t\trows = read_tsv(file_name)\n\t\tsetattr(path, attr_name, rows)\n\n\tdef _load_sequence(self, file_path):\n\t\tfrom Bio import SeqIO\n\n\t\twith open(file_path, \"r\") as handle:\n\t\t\tfor record in SeqIO.parse(handle, \"fasta\"):\n\t\t\t\treturn record.seq\n\n\tdef _load_parameters(self, dir_name, file_name):\n\t\tpath = self\n\t\tfor sub_path in file_name[len(dir_name) + 1:].split(os.path.sep)[:-1]:\n\t\t\tif not hasattr(path, sub_path):\n\t\t\t\tsetattr(path, sub_path, DataStore())\n\t\t\tpath = getattr(path, sub_path)\n\t\tattr_name = file_name.split(os.path.sep)[-1].split(\".\")[0]\n\t\tparam_dict = {}\n\n\t\twith io.open(file_name, \"rb\") as csvfile:\n\t\t\treader = tsv.dict_reader(csvfile)\n\t\t\tfor row in reader:\n\t\t\t\tvalue = json.loads(row['value'])\n\t\t\t\tif row['units'] != '':\n\t\t\t\t\t# `eval()` the units [risky!] then strip it to just a unit\n\t\t\t\t\t# since `a_list * a_float` (like `1.0 [1/s]`) fails, and\n\t\t\t\t\t# `a_list * an_int` repeats the list, which is also broken.\n\t\t\t\t\tunit = eval(row['units'])   # risky!\n\t\t\t\t\tunit = units.getUnit(unit)  # strip\n\t\t\t\t\tvalue = value * unit\n\t\t\t\tparam_dict[row['name']] = value\n\n\t\tsetattr(path, attr_name, param_dict)\n\n\tdef _prune_data(self):\n\t\t\"\"\"\n\t\tRemove rows that are specified to be removed. Data will only be removed\n\t\tif all data in a row in the file specifying rows to be removed matches\n\t\tthe same columns in the raw data file.\n\t\t\"\"\"\n\t\t# Check each pair of files to be removed\n\t\tfor data_attr, attr_to_remove in self.removed_data.items():\n\t\t\t# Build the set of data to identify rows to be removed\n\t\t\tdata_to_remove = getattr(self, attr_to_remove.split('.')[0])\n\t\t\tfor attr in attr_to_remove.split('.')[1:]:\n\t\t\t\tdata_to_remove = getattr(data_to_remove, attr)\n\t\t\tremoved_cols = list(data_to_remove[0].keys())\n\t\t\tids_to_remove = set()\n\t\t\tfor row in data_to_remove:\n\t\t\t\tids_to_remove.add(tuple([row[col] for col in removed_cols]))\n\n\t\t\t# Remove any matching rows\n\t\t\tdata = getattr(self, data_attr)\n\t\t\tn_entries = len(data)\n\t\t\tremoved_ids = set()\n\t\t\tfor i, row in enumerate(data[::-1]):\n\t\t\t\tchecked_id = tuple([row[col] for col in removed_cols])\n\t\t\t\tif checked_id in ids_to_remove:\n\t\t\t\t\tdata.pop(n_entries - i - 1)\n\t\t\t\t\tremoved_ids.add(checked_id)\n\n\t\t\t# Print warnings for entries that were marked to be removed that\n\t\t\t# does not exist in the original data file. Fold changes are\n\t\t\t# excluded since the original entries are split between two files.\n\t\t\tif not data_attr.startswith('fold_changes'):\n\t\t\t\tfor unremoved_id in (ids_to_remove - removed_ids):\n\t\t\t\t\tprint(f'Warning: Could not remove row {unremoved_id} '\n\t\t\t\t\t\t  f'in flat file {data_attr} because the row does not '\n\t\t\t\t\t\t  f'exist.')\n\n\tdef _join_data(self):\n\t\t\"\"\"\n\t\tAdd rows that are specified in additional files. Data will only be added\n\t\tif all the loaded columns from both datasets match.\n\t\t\"\"\"\n\t\t# Join data for each file with data to be added\n\t\tfor data_attr, attr_to_add in self.added_data.items():\n\t\t\t# Get datasets to join\n\t\t\tdata = getattr(self, data_attr.split('.')[0])\n\t\t\tfor attr in data_attr.split('.')[1:]:\n\t\t\t\tdata = getattr(data, attr)\n\n\t\t\tadded_data = getattr(self, attr_to_add.split('.')[0])\n\t\t\tfor attr in attr_to_add.split('.')[1:]:\n\t\t\t\tadded_data = getattr(added_data, attr)\n\n\t\t\tif added_data:  # Some new gene additional files may be empty\n\t\t\t\t# Check columns are the same for each dataset\n\t\t\t\tcol_diff = set(data[0].keys()).symmetric_difference(added_data[0].keys())\n\t\t\t\tif col_diff:\n\t\t\t\t\traise ValueError(f'Could not join datasets {data_attr} and {attr_to_add} '\n\t\t\t\t\t\tf'because columns do not match (different columns: {col_diff}).')\n\n\t\t\t# Join datasets\n\t\t\tfor row in added_data:\n\t\t\t\tdata.append(row)\n\n\tdef _modify_data(self):\n\t\t\"\"\"\n\t\tModify entires in rows that are specified to be modified. Rows must be\n\t\tidentified by their entries in the first column (usually the ID column).\n\t\t\"\"\"\n\t\t# Check each pair of files to be modified\n\t\tfor data_attr, modify_attr in self.modified_data.items():\n\t\t\t# Build the set of data to identify rows to be modified\n\t\t\tdata_to_modify = getattr(self, modify_attr.split('.')[0])\n\t\t\tfor attr in modify_attr.split('.')[1:]:\n\t\t\t\tdata_to_modify = getattr(data_to_modify, attr)\n\n\t\t\tdata = getattr(self, data_attr)\n\n\t\t\t# If modifying a parameter file, replace values in dictionary\n\t\t\tif data_attr in self.parameter_file_attribute_names:\n\t\t\t\tfor key, value in data_to_modify.items():\n\t\t\t\t\tif key not in data:\n\t\t\t\t\t\traise ValueError(f'Could not modify data {data_attr}'\n\t\t\t\t\t\t\tf'with {modify_attr} because the name {key} does '\n\t\t\t\t\t\t\tf'not exist in {data_attr}.')\n\n\t\t\t\t\tdata[key] = value\n\n\t\t\t# If modifying a table file, replace rows\n\t\t\telse:\n\t\t\t\tid_col_name = list(data_to_modify[0].keys())[0]\n\n\t\t\t\tid_to_modified_cols = {}\n\t\t\t\tfor row in data_to_modify:\n\t\t\t\t\tid_to_modified_cols[row[id_col_name]] = row\n\n\t\t\t\t# Modify any matching rows with identical IDs\n\t\t\t\tif list(data[0].keys())[0] != id_col_name:\n\t\t\t\t\traise ValueError(f'Could not modify data {data_attr} with '\n\t\t\t\t\t\tf'{modify_attr} because the names of the first columns '\n\t\t\t\t\t\tf'do not match.')\n\n\t\t\t\tmodified_entry_ids = set()\n\t\t\t\tfor i, row in enumerate(data):\n\t\t\t\t\tif row[id_col_name] in id_to_modified_cols:\n\t\t\t\t\t\tmodified_cols = id_to_modified_cols[row[id_col_name]]\n\t\t\t\t\t\tfor col_name in data[i]:\n\t\t\t\t\t\t\tif col_name in modified_cols:\n\t\t\t\t\t\t\t\tdata[i][col_name] = modified_cols[col_name]\n\t\t\t\t\t\tmodified_entry_ids.add(row[id_col_name])\n\n\t\t\t\t# Check for entries in modification data that do not exist in\n\t\t\t\t# original data\n\t\t\t\tid_diff = set(id_to_modified_cols.keys()).symmetric_difference(\n\t\t\t\t\tmodified_entry_ids)\n\t\t\t\tif id_diff:\n\t\t\t\t\traise ValueError(f'Could not modify data {data_attr} with '\n\t\t\t\t\t\tf'{modify_attr} because of one or more entries in '\n\t\t\t\t\t\tf'{modify_attr} that do not exist in {data_attr} '\n\t\t\t\t\t\tf'(nonexistent entries: {id_diff}).')\n\n\tdef _check_new_gene_ids(self, nested_attr):\n\t\t\"\"\"\n\t\tCheck to ensure each new gene, RNA, and protein id starts with NG.\n\t\t\"\"\"\n\t\tnested_data = getattr(self, nested_attr[:-1].split('.')[0])\n\t\tfor attr in nested_attr[:-1].split('.')[1:]:\n\t\t\tnested_data = getattr(nested_data, attr)\n\n\t\tnew_genes_data = getattr(nested_data, 'genes')\n\t\tnew_RNA_data = getattr(nested_data,'rnas')\n\t\tnew_protein_data = getattr(nested_data,'proteins')\n\n\t\tfor row in new_genes_data:\n\t\t\tassert row['id'].startswith(\"NG\"), (\n\t\t\t\t\"ids of new genes must start with NG\")\n\t\tfor row in new_RNA_data:\n\t\t\tassert row['id'].startswith(\"NG\"), (\n\t\t\t\t\"ids of new gene RNAs must start with NG\")\n\t\tfor row in new_protein_data:\n\t\t\tassert row['id'].startswith(\"NG\"), (\n\t\t\t\t\"ids of new gene proteins must start with NG\")\n\t\treturn\n\n\tdef _update_gene_insertion_location(self, nested_attr):\n\t\t\"\"\"\n\t\tUpdate insertion location of new genes to prevent conflicts.\n\t\t\"\"\"\n\t\tgenes_data = getattr(self, 'genes')\n\t\ttu_data = getattr(self, 'transcription_units')\n\t\tdna_sites_data = getattr(self, 'dna_sites')\n\n\t\tnested_data = getattr(self, nested_attr[:-1].split('.')[0])\n\t\tfor attr in nested_attr[:-1].split('.')[1:]:\n\t\t\tnested_data = getattr(nested_data, attr)\n\n\t\tinsert_loc_data = getattr(nested_data, 'insertion_location')\n\n\t\tassert len(insert_loc_data) == 1, (\n\t\t\t'each noncontiguous insertion should be in its own directory')\n\t\tinsert_pos = insert_loc_data[0]['insertion_pos']\n\n\t\tif not tu_data:\n\t\t\t# Check if specified insertion location is in another gene\n\t\t\tdata_to_check = genes_data.copy()\n\t\telse:\n\t\t\t# Check if specified insertion location is in a transcription unit\n\t\t\tdata_to_check = tu_data.copy()\n\n\t\t# Add important DNA sites to the list of locations to check\n\t\t# TODO: Check for other DNA sites if we include any in the future\n\t\tsites_data_to_check = [\n\t\t\tsite for site in dna_sites_data if site['common_name'] == 'oriC' or\n\t\t\tsite['common_name'] == 'TerC']\n\t\tdata_to_check += sites_data_to_check\n\n\t\tconflicts = [\n\t\t\trow for row in data_to_check\n\t\t\tif ((row['left_end_pos'] is not None) and (row['left_end_pos'] != ''))\n\t\t\tand ((row['right_end_pos'] is not None) and (row['left_end_pos'] != ''))\n\t\t\tand (row['left_end_pos'] < insert_pos)\n\t\t\tand (row['right_end_pos'] >= insert_pos)]\n\t\t# Change insertion location to after conflicts\n\t\tif conflicts:\n\t\t\tshift = max([sub['right_end_pos'] for sub in conflicts]) - insert_pos + 1\n\t\t\tinsert_pos = insert_pos + shift\n\n\t\treturn insert_pos\n\n\tdef _update_global_coordinates(self, data, insert_pos, insert_len):\n\t\t\"\"\"\n\t\tUpdates the left and right end positions for all elements in data if\n\t\ttheir positions will be impacted by the new gene insertion.\n\n\t\tArgs:\n\t\t\tdata: Data attribute to update\n\t\t\tinsert_pos: Location of new gene insertion\n\t\t\tinsert_len: Length of new gene insertion\n\n\t\t\"\"\"\n\t\tfor row in data:\n\t\t\tleft = row['left_end_pos']\n\t\t\tright = row['right_end_pos']\n\t\t\tif ((left is not None and left != '')\n\t\t\t\t\tand (right is not None and right != '')\n\t\t\t\t\tand left >= insert_pos):\n\t\t\t\trow.update({'left_end_pos': left + insert_len})\n\t\t\t\trow.update({'right_end_pos': right + insert_len})\n\n\tdef _update_gene_locations(self, nested_attr, insert_pos):\n\t\t\"\"\"\n\t\tModify positions of original genes based upon the insertion location\n\t\tof new genes. Returns end position of the gene insertion.\n\t\t\"\"\"\n\t\tgenes_data = getattr(self, 'genes')\n\t\ttu_data = getattr(self, 'transcription_units')\n\t\tdna_sites_data = getattr(self, 'dna_sites')\n\n\t\tnested_data = getattr(self, nested_attr[:-1].split('.')[0])\n\t\tfor attr in nested_attr[:-1].split('.')[1:]:\n\t\t\tnested_data = getattr(nested_data, attr)\n\n\t\tnew_genes_data = getattr(nested_data,'genes')\n\t\tnew_genes_data = sorted(new_genes_data, key=lambda d: d['left_end_pos'])\n\n\t\tfor i in range(len(new_genes_data) - 1):\n\t\t\tassert (new_genes_data[i+1]['left_end_pos']\n\t\t\t\t== new_genes_data[i]['right_end_pos'] + 1), (\n\t\t\t\t\"gaps in new gene insertions are not supported at this time\")\n\n\t\tinsert_end = new_genes_data[-1]['right_end_pos'] + insert_pos\n\t\tinsert_len = insert_end - insert_pos + 1\n\n\t\t# Update global positions of original genes\n\t\tself._update_global_coordinates(genes_data, insert_pos, insert_len)\n\n\t\t# Update global positions of transcription units\n\t\tif tu_data:\n\t\t\tself._update_global_coordinates(tu_data, insert_pos, insert_len)\n\n\t\t# Update DNA site positions\n\t\t# (including the origin and terminus of replication)\n\t\tself._update_global_coordinates(dna_sites_data, insert_pos, insert_len)\n\n\t\t# Change relative insertion positions to global in reference genome\n\t\tfor row in new_genes_data:\n\t\t\tleft = row['left_end_pos']\n\t\t\tright = row['right_end_pos']\n\t\t\trow.update({'left_end_pos': left + insert_pos})\n\t\t\trow.update({'right_end_pos': right + insert_pos})\n\n\t\treturn insert_end\n\n\tdef _get_new_gene_sequence(self, nested_attr):\n\t\t\"\"\"\n\t\tDetermine genome sequnce for insertion using the sequences and\n\t\trelative locations of the new genes.\n\t\t\"\"\"\n\t\tfrom Bio import Seq\n\n\t\tnested_data = getattr(self, nested_attr[:-1].split('.')[0])\n\t\tfor attr in nested_attr[:-1].split('.')[1:]:\n\t\t\tnested_data = getattr(nested_data, attr)\n\n\t\tnew_genes_data = getattr(nested_data,'genes')\n\t\tseq_data = getattr(nested_data,'gene_sequences')\n\n\t\tinsertion_seq = Seq.Seq('')\n\t\tnew_genes_data = sorted(new_genes_data, key=lambda d: d['left_end_pos'])\n\t\tassert new_genes_data[0]['left_end_pos'] == 0, (\n\t\t\t'first gene in new sequence must start at relative coordinate 0')\n\n\t\tfor gene in new_genes_data:\n\t\t\tif gene['direction'] == \"+\":\n\t\t\t\tseq_row = next((\n\t\t\t\t\trow for row in seq_data if row['id'] == gene['id']), None)\n\t\t\t\tseq_string = seq_row['gene_seq']\n\t\t\t\tseq_addition = Seq.Seq(seq_string)\n\t\t\t\tinsertion_seq += seq_addition\n\t\t\telse:\n\t\t\t\tseq_row = next((\n\t\t\t\t\trow for row in seq_data if row['id'] == gene['id']), None)\n\t\t\t\tseq_string = seq_row['gene_seq']\n\t\t\t\tseq_addition = Seq.Seq(seq_string)\n\t\t\t\tinsertion_seq += seq_addition.reverse_complement()\n\n\t\t\tassert (len(seq_addition) == (\n\t\t\t\tgene['right_end_pos'] - gene['left_end_pos'] + 1)), (\n\t\t\t\tf\"left and right end positions must agree with actual \"\n\t\t\t\tf\"sequence length for {gene['id']}\")\n\n\t\treturn insertion_seq\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/reconstruction/ecoli/knowledge_base_raw.py b/reconstruction/ecoli/knowledge_base_raw.py
--- a/reconstruction/ecoli/knowledge_base_raw.py	
+++ b/reconstruction/ecoli/knowledge_base_raw.py	
@@ -57,6 +57,7 @@
 	"ppgpp_regulation.tsv",
 	"ppgpp_regulation_added.tsv",
 	"ppgpp_regulation_removed.tsv",
+	"protein_half_lives_gupta.tsv",
 	"protein_half_lives_measured.tsv",
 	"protein_half_lives_n_end_rule.tsv",
 	"protein_half_lives_pulsed_silac.tsv",
